{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_RJPHSIttxbg",
        "outputId": "afe33b80-bd54-454a-ce6e-64bdb7f7a5d8"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "FfSglge_vtMX"
      },
      "outputs": [],
      "source": [
        "datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "    rotation_range = 15,\n",
        "    horizontal_flip= True,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1\n",
        ")\n",
        "datagen.fit(x_train)\n",
        "\n",
        "x_train = x_train.astype(\"float32\")\n",
        "x_test = x_test.astype(\"float32\")\n",
        "mean = np.mean(x_train)\n",
        "std = np.std(x_train)\n",
        "x_test = (x_test - mean) / std\n",
        "x_train = (x_train - mean) / std\n",
        "y_train = tf.keras.utils.to_categorical(y_train, 10)\n",
        "y_test = tf.keras.utils.to_categorical(y_test, 10)\n",
        "def lr_schedule(epoch):\n",
        "  if epoch > 200 :\n",
        "    return 0.0001\n",
        "  if epoch > 80 :\n",
        "    return 0.001\n",
        "  if epoch > 50 :\n",
        "    return 0.005\n",
        "  return 0.01\n",
        "  \n",
        "reduced_lr = tf.keras.callbacks.LearningRateScheduler(lr_schedule)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "def bottleneck(t, inc, ouc, n, s, x):\n",
        "    x_input = x\n",
        "    strides = [s] + [1] * (n - 1)\n",
        "    for stride in strides:\n",
        "        x = tf.keras.layers.Conv2D(filters = inc * t, kernel_size= (1, 1), strides = 1, padding = 'SAME'\n",
        "                                   , kernel_initializer=tf.keras.initializers.he_normal())(x)\n",
        "        x = tf.keras.layers.BatchNormalization(epsilon=1e-3, momentum=0.999)(x)\n",
        "        x = tf.nn.relu6(x)\n",
        "        x = tf.keras.layers.DepthwiseConv2D(kernel_size= (3, 3), strides=stride,padding='same')(x)\n",
        "        x = tf.keras.layers.BatchNormalization(epsilon=1e-3, momentum=0.999)(x)\n",
        "        x = tf.nn.relu6(x)\n",
        "        x = tf.keras.layers.Conv2D(filters = ouc, kernel_size=(1, 1), strides=1,  padding='same')(x)\n",
        "        x = tf.keras.layers.BatchNormalization(epsilon=1e-3, momentum=0.999)(x)\n",
        "        if stride == 1 :\n",
        "            x_input = tf.keras.layers.Conv2D(filters = ouc, kernel_size=(1, 1), strides=1,  padding='same')(x)\n",
        "            x = tf.keras.layers.Add()([x, x_input])\n",
        "    return x\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 32, 32, 3)]  0           []                               \n",
            "                                                                                                  \n",
            " conv2d (Conv2D)                (None, 32, 32, 32)   896         ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " batch_normalization (BatchNorm  (None, 32, 32, 32)  128         ['conv2d[0][0]']                 \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " conv2d_1 (Conv2D)              (None, 32, 32, 32)   1056        ['batch_normalization[0][0]']    \n",
            "                                                                                                  \n",
            " batch_normalization_1 (BatchNo  (None, 32, 32, 32)  128         ['conv2d_1[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " tf.nn.relu6 (TFOpLambda)       (None, 32, 32, 32)   0           ['batch_normalization_1[0][0]']  \n",
            "                                                                                                  \n",
            " depthwise_conv2d (DepthwiseCon  (None, 32, 32, 32)  320         ['tf.nn.relu6[0][0]']            \n",
            " v2D)                                                                                             \n",
            "                                                                                                  \n",
            " batch_normalization_2 (BatchNo  (None, 32, 32, 32)  128         ['depthwise_conv2d[0][0]']       \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " tf.nn.relu6_1 (TFOpLambda)     (None, 32, 32, 32)   0           ['batch_normalization_2[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_2 (Conv2D)              (None, 32, 32, 16)   528         ['tf.nn.relu6_1[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_3 (BatchNo  (None, 32, 32, 16)  64          ['conv2d_2[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv2d_3 (Conv2D)              (None, 32, 32, 16)   272         ['batch_normalization_3[0][0]']  \n",
            "                                                                                                  \n",
            " add (Add)                      (None, 32, 32, 16)   0           ['batch_normalization_3[0][0]',  \n",
            "                                                                  'conv2d_3[0][0]']               \n",
            "                                                                                                  \n",
            " dropout (Dropout)              (None, 32, 32, 16)   0           ['add[0][0]']                    \n",
            "                                                                                                  \n",
            " conv2d_4 (Conv2D)              (None, 32, 32, 96)   1632        ['dropout[0][0]']                \n",
            "                                                                                                  \n",
            " batch_normalization_4 (BatchNo  (None, 32, 32, 96)  384         ['conv2d_4[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " tf.nn.relu6_2 (TFOpLambda)     (None, 32, 32, 96)   0           ['batch_normalization_4[0][0]']  \n",
            "                                                                                                  \n",
            " depthwise_conv2d_1 (DepthwiseC  (None, 32, 32, 96)  960         ['tf.nn.relu6_2[0][0]']          \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_5 (BatchNo  (None, 32, 32, 96)  384         ['depthwise_conv2d_1[0][0]']     \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " tf.nn.relu6_3 (TFOpLambda)     (None, 32, 32, 96)   0           ['batch_normalization_5[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_5 (Conv2D)              (None, 32, 32, 24)   2328        ['tf.nn.relu6_3[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_6 (BatchNo  (None, 32, 32, 24)  96          ['conv2d_5[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv2d_6 (Conv2D)              (None, 32, 32, 24)   600         ['batch_normalization_6[0][0]']  \n",
            "                                                                                                  \n",
            " add_1 (Add)                    (None, 32, 32, 24)   0           ['batch_normalization_6[0][0]',  \n",
            "                                                                  'conv2d_6[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_7 (Conv2D)              (None, 32, 32, 96)   2400        ['add_1[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_7 (BatchNo  (None, 32, 32, 96)  384         ['conv2d_7[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " tf.nn.relu6_4 (TFOpLambda)     (None, 32, 32, 96)   0           ['batch_normalization_7[0][0]']  \n",
            "                                                                                                  \n",
            " depthwise_conv2d_2 (DepthwiseC  (None, 32, 32, 96)  960         ['tf.nn.relu6_4[0][0]']          \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_8 (BatchNo  (None, 32, 32, 96)  384         ['depthwise_conv2d_2[0][0]']     \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " tf.nn.relu6_5 (TFOpLambda)     (None, 32, 32, 96)   0           ['batch_normalization_8[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_8 (Conv2D)              (None, 32, 32, 24)   2328        ['tf.nn.relu6_5[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_9 (BatchNo  (None, 32, 32, 24)  96          ['conv2d_8[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv2d_9 (Conv2D)              (None, 32, 32, 24)   600         ['batch_normalization_9[0][0]']  \n",
            "                                                                                                  \n",
            " add_2 (Add)                    (None, 32, 32, 24)   0           ['batch_normalization_9[0][0]',  \n",
            "                                                                  'conv2d_9[0][0]']               \n",
            "                                                                                                  \n",
            " dropout_1 (Dropout)            (None, 32, 32, 24)   0           ['add_2[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_10 (Conv2D)             (None, 32, 32, 144)  3600        ['dropout_1[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_10 (BatchN  (None, 32, 32, 144)  576        ['conv2d_10[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " tf.nn.relu6_6 (TFOpLambda)     (None, 32, 32, 144)  0           ['batch_normalization_10[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_3 (DepthwiseC  (None, 32, 32, 144)  1440       ['tf.nn.relu6_6[0][0]']          \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_11 (BatchN  (None, 32, 32, 144)  576        ['depthwise_conv2d_3[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " tf.nn.relu6_7 (TFOpLambda)     (None, 32, 32, 144)  0           ['batch_normalization_11[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_11 (Conv2D)             (None, 32, 32, 32)   4640        ['tf.nn.relu6_7[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_12 (BatchN  (None, 32, 32, 32)  128         ['conv2d_11[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_12 (Conv2D)             (None, 32, 32, 32)   1056        ['batch_normalization_12[0][0]'] \n",
            "                                                                                                  \n",
            " add_3 (Add)                    (None, 32, 32, 32)   0           ['batch_normalization_12[0][0]', \n",
            "                                                                  'conv2d_12[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_13 (Conv2D)             (None, 32, 32, 144)  4752        ['add_3[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_13 (BatchN  (None, 32, 32, 144)  576        ['conv2d_13[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " tf.nn.relu6_8 (TFOpLambda)     (None, 32, 32, 144)  0           ['batch_normalization_13[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_4 (DepthwiseC  (None, 32, 32, 144)  1440       ['tf.nn.relu6_8[0][0]']          \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_14 (BatchN  (None, 32, 32, 144)  576        ['depthwise_conv2d_4[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " tf.nn.relu6_9 (TFOpLambda)     (None, 32, 32, 144)  0           ['batch_normalization_14[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_14 (Conv2D)             (None, 32, 32, 32)   4640        ['tf.nn.relu6_9[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_15 (BatchN  (None, 32, 32, 32)  128         ['conv2d_14[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_15 (Conv2D)             (None, 32, 32, 32)   1056        ['batch_normalization_15[0][0]'] \n",
            "                                                                                                  \n",
            " add_4 (Add)                    (None, 32, 32, 32)   0           ['batch_normalization_15[0][0]', \n",
            "                                                                  'conv2d_15[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_16 (Conv2D)             (None, 32, 32, 144)  4752        ['add_4[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_16 (BatchN  (None, 32, 32, 144)  576        ['conv2d_16[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " tf.nn.relu6_10 (TFOpLambda)    (None, 32, 32, 144)  0           ['batch_normalization_16[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_5 (DepthwiseC  (None, 32, 32, 144)  1440       ['tf.nn.relu6_10[0][0]']         \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_17 (BatchN  (None, 32, 32, 144)  576        ['depthwise_conv2d_5[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " tf.nn.relu6_11 (TFOpLambda)    (None, 32, 32, 144)  0           ['batch_normalization_17[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_17 (Conv2D)             (None, 32, 32, 32)   4640        ['tf.nn.relu6_11[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_18 (BatchN  (None, 32, 32, 32)  128         ['conv2d_17[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_18 (Conv2D)             (None, 32, 32, 32)   1056        ['batch_normalization_18[0][0]'] \n",
            "                                                                                                  \n",
            " add_5 (Add)                    (None, 32, 32, 32)   0           ['batch_normalization_18[0][0]', \n",
            "                                                                  'conv2d_18[0][0]']              \n",
            "                                                                                                  \n",
            " dropout_2 (Dropout)            (None, 32, 32, 32)   0           ['add_5[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_19 (Conv2D)             (None, 32, 32, 192)  6336        ['dropout_2[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_19 (BatchN  (None, 32, 32, 192)  768        ['conv2d_19[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " tf.nn.relu6_12 (TFOpLambda)    (None, 32, 32, 192)  0           ['batch_normalization_19[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_6 (DepthwiseC  (None, 16, 16, 192)  1920       ['tf.nn.relu6_12[0][0]']         \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_20 (BatchN  (None, 16, 16, 192)  768        ['depthwise_conv2d_6[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " tf.nn.relu6_13 (TFOpLambda)    (None, 16, 16, 192)  0           ['batch_normalization_20[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_20 (Conv2D)             (None, 16, 16, 64)   12352       ['tf.nn.relu6_13[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_21 (BatchN  (None, 16, 16, 64)  256         ['conv2d_20[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_21 (Conv2D)             (None, 16, 16, 192)  12480       ['batch_normalization_21[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_22 (BatchN  (None, 16, 16, 192)  768        ['conv2d_21[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " tf.nn.relu6_14 (TFOpLambda)    (None, 16, 16, 192)  0           ['batch_normalization_22[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_7 (DepthwiseC  (None, 16, 16, 192)  1920       ['tf.nn.relu6_14[0][0]']         \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_23 (BatchN  (None, 16, 16, 192)  768        ['depthwise_conv2d_7[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " tf.nn.relu6_15 (TFOpLambda)    (None, 16, 16, 192)  0           ['batch_normalization_23[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_22 (Conv2D)             (None, 16, 16, 64)   12352       ['tf.nn.relu6_15[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_24 (BatchN  (None, 16, 16, 64)  256         ['conv2d_22[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_23 (Conv2D)             (None, 16, 16, 64)   4160        ['batch_normalization_24[0][0]'] \n",
            "                                                                                                  \n",
            " add_6 (Add)                    (None, 16, 16, 64)   0           ['batch_normalization_24[0][0]', \n",
            "                                                                  'conv2d_23[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_24 (Conv2D)             (None, 16, 16, 192)  12480       ['add_6[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_25 (BatchN  (None, 16, 16, 192)  768        ['conv2d_24[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " tf.nn.relu6_16 (TFOpLambda)    (None, 16, 16, 192)  0           ['batch_normalization_25[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_8 (DepthwiseC  (None, 16, 16, 192)  1920       ['tf.nn.relu6_16[0][0]']         \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_26 (BatchN  (None, 16, 16, 192)  768        ['depthwise_conv2d_8[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " tf.nn.relu6_17 (TFOpLambda)    (None, 16, 16, 192)  0           ['batch_normalization_26[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_25 (Conv2D)             (None, 16, 16, 64)   12352       ['tf.nn.relu6_17[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_27 (BatchN  (None, 16, 16, 64)  256         ['conv2d_25[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_26 (Conv2D)             (None, 16, 16, 64)   4160        ['batch_normalization_27[0][0]'] \n",
            "                                                                                                  \n",
            " add_7 (Add)                    (None, 16, 16, 64)   0           ['batch_normalization_27[0][0]', \n",
            "                                                                  'conv2d_26[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_27 (Conv2D)             (None, 16, 16, 192)  12480       ['add_7[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_28 (BatchN  (None, 16, 16, 192)  768        ['conv2d_27[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " tf.nn.relu6_18 (TFOpLambda)    (None, 16, 16, 192)  0           ['batch_normalization_28[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_9 (DepthwiseC  (None, 16, 16, 192)  1920       ['tf.nn.relu6_18[0][0]']         \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_29 (BatchN  (None, 16, 16, 192)  768        ['depthwise_conv2d_9[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " tf.nn.relu6_19 (TFOpLambda)    (None, 16, 16, 192)  0           ['batch_normalization_29[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_28 (Conv2D)             (None, 16, 16, 64)   12352       ['tf.nn.relu6_19[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_30 (BatchN  (None, 16, 16, 64)  256         ['conv2d_28[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_29 (Conv2D)             (None, 16, 16, 64)   4160        ['batch_normalization_30[0][0]'] \n",
            "                                                                                                  \n",
            " add_8 (Add)                    (None, 16, 16, 64)   0           ['batch_normalization_30[0][0]', \n",
            "                                                                  'conv2d_29[0][0]']              \n",
            "                                                                                                  \n",
            " dropout_3 (Dropout)            (None, 16, 16, 64)   0           ['add_8[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_30 (Conv2D)             (None, 16, 16, 384)  24960       ['dropout_3[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_31 (BatchN  (None, 16, 16, 384)  1536       ['conv2d_30[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " tf.nn.relu6_20 (TFOpLambda)    (None, 16, 16, 384)  0           ['batch_normalization_31[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_10 (Depthwise  (None, 16, 16, 384)  3840       ['tf.nn.relu6_20[0][0]']         \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_32 (BatchN  (None, 16, 16, 384)  1536       ['depthwise_conv2d_10[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " tf.nn.relu6_21 (TFOpLambda)    (None, 16, 16, 384)  0           ['batch_normalization_32[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_31 (Conv2D)             (None, 16, 16, 96)   36960       ['tf.nn.relu6_21[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_33 (BatchN  (None, 16, 16, 96)  384         ['conv2d_31[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_32 (Conv2D)             (None, 16, 16, 96)   9312        ['batch_normalization_33[0][0]'] \n",
            "                                                                                                  \n",
            " add_9 (Add)                    (None, 16, 16, 96)   0           ['batch_normalization_33[0][0]', \n",
            "                                                                  'conv2d_32[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_33 (Conv2D)             (None, 16, 16, 384)  37248       ['add_9[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_34 (BatchN  (None, 16, 16, 384)  1536       ['conv2d_33[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " tf.nn.relu6_22 (TFOpLambda)    (None, 16, 16, 384)  0           ['batch_normalization_34[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_11 (Depthwise  (None, 16, 16, 384)  3840       ['tf.nn.relu6_22[0][0]']         \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_35 (BatchN  (None, 16, 16, 384)  1536       ['depthwise_conv2d_11[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " tf.nn.relu6_23 (TFOpLambda)    (None, 16, 16, 384)  0           ['batch_normalization_35[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_34 (Conv2D)             (None, 16, 16, 96)   36960       ['tf.nn.relu6_23[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_36 (BatchN  (None, 16, 16, 96)  384         ['conv2d_34[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_35 (Conv2D)             (None, 16, 16, 96)   9312        ['batch_normalization_36[0][0]'] \n",
            "                                                                                                  \n",
            " add_10 (Add)                   (None, 16, 16, 96)   0           ['batch_normalization_36[0][0]', \n",
            "                                                                  'conv2d_35[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_36 (Conv2D)             (None, 16, 16, 384)  37248       ['add_10[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_37 (BatchN  (None, 16, 16, 384)  1536       ['conv2d_36[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " tf.nn.relu6_24 (TFOpLambda)    (None, 16, 16, 384)  0           ['batch_normalization_37[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_12 (Depthwise  (None, 16, 16, 384)  3840       ['tf.nn.relu6_24[0][0]']         \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_38 (BatchN  (None, 16, 16, 384)  1536       ['depthwise_conv2d_12[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " tf.nn.relu6_25 (TFOpLambda)    (None, 16, 16, 384)  0           ['batch_normalization_38[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_37 (Conv2D)             (None, 16, 16, 96)   36960       ['tf.nn.relu6_25[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_39 (BatchN  (None, 16, 16, 96)  384         ['conv2d_37[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_38 (Conv2D)             (None, 16, 16, 96)   9312        ['batch_normalization_39[0][0]'] \n",
            "                                                                                                  \n",
            " add_11 (Add)                   (None, 16, 16, 96)   0           ['batch_normalization_39[0][0]', \n",
            "                                                                  'conv2d_38[0][0]']              \n",
            "                                                                                                  \n",
            " dropout_4 (Dropout)            (None, 16, 16, 96)   0           ['add_11[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_39 (Conv2D)             (None, 16, 16, 576)  55872       ['dropout_4[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_40 (BatchN  (None, 16, 16, 576)  2304       ['conv2d_39[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " tf.nn.relu6_26 (TFOpLambda)    (None, 16, 16, 576)  0           ['batch_normalization_40[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_13 (Depthwise  (None, 8, 8, 576)   5760        ['tf.nn.relu6_26[0][0]']         \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_41 (BatchN  (None, 8, 8, 576)   2304        ['depthwise_conv2d_13[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " tf.nn.relu6_27 (TFOpLambda)    (None, 8, 8, 576)    0           ['batch_normalization_41[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_40 (Conv2D)             (None, 8, 8, 160)    92320       ['tf.nn.relu6_27[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_42 (BatchN  (None, 8, 8, 160)   640         ['conv2d_40[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_41 (Conv2D)             (None, 8, 8, 576)    92736       ['batch_normalization_42[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_43 (BatchN  (None, 8, 8, 576)   2304        ['conv2d_41[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " tf.nn.relu6_28 (TFOpLambda)    (None, 8, 8, 576)    0           ['batch_normalization_43[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_14 (Depthwise  (None, 8, 8, 576)   5760        ['tf.nn.relu6_28[0][0]']         \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_44 (BatchN  (None, 8, 8, 576)   2304        ['depthwise_conv2d_14[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " tf.nn.relu6_29 (TFOpLambda)    (None, 8, 8, 576)    0           ['batch_normalization_44[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_42 (Conv2D)             (None, 8, 8, 160)    92320       ['tf.nn.relu6_29[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_45 (BatchN  (None, 8, 8, 160)   640         ['conv2d_42[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_43 (Conv2D)             (None, 8, 8, 160)    25760       ['batch_normalization_45[0][0]'] \n",
            "                                                                                                  \n",
            " add_12 (Add)                   (None, 8, 8, 160)    0           ['batch_normalization_45[0][0]', \n",
            "                                                                  'conv2d_43[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_44 (Conv2D)             (None, 8, 8, 576)    92736       ['add_12[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_46 (BatchN  (None, 8, 8, 576)   2304        ['conv2d_44[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " tf.nn.relu6_30 (TFOpLambda)    (None, 8, 8, 576)    0           ['batch_normalization_46[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_15 (Depthwise  (None, 8, 8, 576)   5760        ['tf.nn.relu6_30[0][0]']         \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_47 (BatchN  (None, 8, 8, 576)   2304        ['depthwise_conv2d_15[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " tf.nn.relu6_31 (TFOpLambda)    (None, 8, 8, 576)    0           ['batch_normalization_47[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_45 (Conv2D)             (None, 8, 8, 160)    92320       ['tf.nn.relu6_31[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_48 (BatchN  (None, 8, 8, 160)   640         ['conv2d_45[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_46 (Conv2D)             (None, 8, 8, 160)    25760       ['batch_normalization_48[0][0]'] \n",
            "                                                                                                  \n",
            " add_13 (Add)                   (None, 8, 8, 160)    0           ['batch_normalization_48[0][0]', \n",
            "                                                                  'conv2d_46[0][0]']              \n",
            "                                                                                                  \n",
            " dropout_5 (Dropout)            (None, 8, 8, 160)    0           ['add_13[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_47 (Conv2D)             (None, 8, 8, 960)    154560      ['dropout_5[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_49 (BatchN  (None, 8, 8, 960)   3840        ['conv2d_47[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " tf.nn.relu6_32 (TFOpLambda)    (None, 8, 8, 960)    0           ['batch_normalization_49[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_16 (Depthwise  (None, 8, 8, 960)   9600        ['tf.nn.relu6_32[0][0]']         \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_50 (BatchN  (None, 8, 8, 960)   3840        ['depthwise_conv2d_16[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " tf.nn.relu6_33 (TFOpLambda)    (None, 8, 8, 960)    0           ['batch_normalization_50[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_48 (Conv2D)             (None, 8, 8, 320)    307520      ['tf.nn.relu6_33[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_51 (BatchN  (None, 8, 8, 320)   1280        ['conv2d_48[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_49 (Conv2D)             (None, 8, 8, 320)    102720      ['batch_normalization_51[0][0]'] \n",
            "                                                                                                  \n",
            " add_14 (Add)                   (None, 8, 8, 320)    0           ['batch_normalization_51[0][0]', \n",
            "                                                                  'conv2d_49[0][0]']              \n",
            "                                                                                                  \n",
            " dropout_6 (Dropout)            (None, 8, 8, 320)    0           ['add_14[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_50 (Conv2D)             (None, 8, 8, 1280)   410880      ['dropout_6[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_52 (BatchN  (None, 8, 8, 1280)  5120        ['conv2d_50[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " global_average_pooling2d (Glob  (None, 1280)        0           ['batch_normalization_52[0][0]'] \n",
            " alAveragePooling2D)                                                                              \n",
            "                                                                                                  \n",
            " flatten (Flatten)              (None, 1280)         0           ['global_average_pooling2d[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 10)           12810       ['flatten[0][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 2,051,098\n",
            "Trainable params: 2,024,410\n",
            "Non-trainable params: 26,688\n",
            "__________________________________________________________________________________________________\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\optimizer_v2\\gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        }
      ],
      "source": [
        "x_input = tf.keras.layers.Input(shape = (32,32,3))\n",
        "x = tf.keras.layers.Conv2D(filters = 32, kernel_size = (3, 3),  strides= (1, 1), padding = 'SAME', kernel_initializer=tf.keras.initializers.he_normal())(x_input)\n",
        "x = tf.keras.layers.BatchNormalization()(x)\n",
        "x = bottleneck(1, 32, 16, 1, 1, x)\n",
        "x = tf.keras.layers.Dropout(rate = 0.2)(x)\n",
        "x = bottleneck(6, 16, 24, 2, 1, x)\n",
        "x = tf.keras.layers.Dropout(rate = 0.2)(x)\n",
        "x = bottleneck(6, 24, 32, 3, 1, x)\n",
        "x = tf.keras.layers.Dropout(rate = 0.2)(x)\n",
        "x = bottleneck(6, 32, 64, 4, 2, x)\n",
        "x = tf.keras.layers.Dropout(rate = 0.2)(x)\n",
        "x = bottleneck(6, 64, 96, 3, 1, x)\n",
        "x = tf.keras.layers.Dropout(rate = 0.2)(x)\n",
        "x = bottleneck(6, 96, 160, 3, 2, x)\n",
        "x = tf.keras.layers.Dropout(rate = 0.2)(x)\n",
        "x = bottleneck(6, 160, 320, 1, 1, x)\n",
        "x = tf.keras.layers.Dropout(rate = 0.2)(x)\n",
        "x = tf.keras.layers.Conv2D(filters = 1280, kernel_size=(1, 1), strides=1, padding='same', kernel_initializer=tf.keras.initializers.he_normal())(x)\n",
        "x = tf.keras.layers.BatchNormalization(epsilon=1e-3, momentum=0.999)(x)\n",
        "x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
        "x = tf.keras.layers.Flatten()(x)\n",
        "x = tf.keras.layers.Dense(units = 10, activation = 'softmax', kernel_initializer=tf.keras.initializers.he_normal())(x)\n",
        "model = tf.keras.Model(inputs=x_input, outputs = x)\n",
        "model.compile(\n",
        "    loss='categorical_crossentropy',\n",
        "    optimizer=tf.keras.optimizers.SGD(lr=0.045, momentum=0.9),\n",
        "    metrics=['accuracy'],\n",
        ")\n",
        "model.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/250\n",
            "390/390 [==============================] - 101s 233ms/step - loss: 1.8103 - accuracy: 0.3295 - val_loss: 2.3439 - val_accuracy: 0.1000 - lr: 0.0100\n",
            "Epoch 2/250\n",
            "390/390 [==============================] - 89s 227ms/step - loss: 1.4608 - accuracy: 0.4679 - val_loss: 2.3909 - val_accuracy: 0.1000 - lr: 0.0100\n",
            "Epoch 3/250\n",
            "390/390 [==============================] - 89s 228ms/step - loss: 1.3145 - accuracy: 0.5245 - val_loss: 2.4199 - val_accuracy: 0.1000 - lr: 0.0100\n",
            "Epoch 4/250\n",
            "390/390 [==============================] - 89s 228ms/step - loss: 1.2004 - accuracy: 0.5688 - val_loss: 2.4950 - val_accuracy: 0.1000 - lr: 0.0100\n",
            "Epoch 5/250\n",
            "390/390 [==============================] - 89s 228ms/step - loss: 1.1126 - accuracy: 0.6016 - val_loss: 2.5210 - val_accuracy: 0.1000 - lr: 0.0100\n",
            "Epoch 6/250\n",
            "390/390 [==============================] - 89s 229ms/step - loss: 1.0331 - accuracy: 0.6332 - val_loss: 2.5768 - val_accuracy: 0.1000 - lr: 0.0100\n",
            "Epoch 7/250\n",
            "390/390 [==============================] - 89s 229ms/step - loss: 0.9655 - accuracy: 0.6602 - val_loss: 2.5636 - val_accuracy: 0.1000 - lr: 0.0100\n",
            "Epoch 8/250\n",
            "390/390 [==============================] - 89s 229ms/step - loss: 0.9087 - accuracy: 0.6794 - val_loss: 2.5819 - val_accuracy: 0.1934 - lr: 0.0100\n",
            "Epoch 9/250\n",
            "390/390 [==============================] - 90s 230ms/step - loss: 0.8659 - accuracy: 0.6941 - val_loss: 2.5056 - val_accuracy: 0.2298 - lr: 0.0100\n",
            "Epoch 10/250\n",
            "390/390 [==============================] - 89s 229ms/step - loss: 0.8123 - accuracy: 0.7156 - val_loss: 2.2606 - val_accuracy: 0.2520 - lr: 0.0100\n",
            "Epoch 11/250\n",
            "390/390 [==============================] - 89s 228ms/step - loss: 0.7775 - accuracy: 0.7268 - val_loss: 1.6584 - val_accuracy: 0.4373 - lr: 0.0100\n",
            "Epoch 12/250\n",
            "390/390 [==============================] - 89s 228ms/step - loss: 0.7507 - accuracy: 0.7376 - val_loss: 0.9390 - val_accuracy: 0.6873 - lr: 0.0100\n",
            "Epoch 13/250\n",
            "390/390 [==============================] - 90s 230ms/step - loss: 0.7163 - accuracy: 0.7504 - val_loss: 0.8064 - val_accuracy: 0.7169 - lr: 0.0100\n",
            "Epoch 14/250\n",
            "390/390 [==============================] - 89s 229ms/step - loss: 0.6917 - accuracy: 0.7595 - val_loss: 0.8786 - val_accuracy: 0.7124 - lr: 0.0100\n",
            "Epoch 15/250\n",
            "390/390 [==============================] - 90s 230ms/step - loss: 0.6679 - accuracy: 0.7658 - val_loss: 1.3878 - val_accuracy: 0.6257 - lr: 0.0100\n",
            "Epoch 16/250\n",
            "390/390 [==============================] - 89s 228ms/step - loss: 0.6442 - accuracy: 0.7769 - val_loss: 1.0390 - val_accuracy: 0.6857 - lr: 0.0100\n",
            "Epoch 17/250\n",
            "390/390 [==============================] - 89s 228ms/step - loss: 0.6226 - accuracy: 0.7818 - val_loss: 1.0916 - val_accuracy: 0.7034 - lr: 0.0100\n",
            "Epoch 18/250\n",
            "390/390 [==============================] - 89s 228ms/step - loss: 0.6054 - accuracy: 0.7883 - val_loss: 1.0564 - val_accuracy: 0.7015 - lr: 0.0100\n",
            "Epoch 19/250\n",
            "390/390 [==============================] - 89s 228ms/step - loss: 0.5833 - accuracy: 0.7965 - val_loss: 1.5999 - val_accuracy: 0.6145 - lr: 0.0100\n",
            "Epoch 20/250\n",
            "390/390 [==============================] - 89s 228ms/step - loss: 0.5677 - accuracy: 0.8003 - val_loss: 1.0375 - val_accuracy: 0.7263 - lr: 0.0100\n",
            "Epoch 21/250\n",
            "390/390 [==============================] - 89s 227ms/step - loss: 0.5551 - accuracy: 0.8062 - val_loss: 1.2149 - val_accuracy: 0.6869 - lr: 0.0100\n",
            "Epoch 22/250\n",
            "390/390 [==============================] - 89s 228ms/step - loss: 0.5455 - accuracy: 0.8093 - val_loss: 1.3599 - val_accuracy: 0.6563 - lr: 0.0100\n",
            "Epoch 23/250\n",
            "390/390 [==============================] - 89s 228ms/step - loss: 0.5296 - accuracy: 0.8156 - val_loss: 0.8306 - val_accuracy: 0.7506 - lr: 0.0100\n",
            "Epoch 24/250\n",
            "390/390 [==============================] - 89s 228ms/step - loss: 0.5121 - accuracy: 0.8204 - val_loss: 1.0619 - val_accuracy: 0.7252 - lr: 0.0100\n",
            "Epoch 25/250\n",
            "390/390 [==============================] - 89s 228ms/step - loss: 0.5066 - accuracy: 0.8225 - val_loss: 0.8700 - val_accuracy: 0.7515 - lr: 0.0100\n",
            "Epoch 26/250\n",
            "390/390 [==============================] - 89s 227ms/step - loss: 0.4938 - accuracy: 0.8277 - val_loss: 1.0886 - val_accuracy: 0.7123 - lr: 0.0100\n",
            "Epoch 27/250\n",
            "390/390 [==============================] - 89s 227ms/step - loss: 0.4803 - accuracy: 0.8326 - val_loss: 0.7415 - val_accuracy: 0.7862 - lr: 0.0100\n",
            "Epoch 28/250\n",
            "390/390 [==============================] - 89s 228ms/step - loss: 0.4769 - accuracy: 0.8342 - val_loss: 0.9327 - val_accuracy: 0.7503 - lr: 0.0100\n",
            "Epoch 29/250\n",
            "390/390 [==============================] - 89s 227ms/step - loss: 0.4696 - accuracy: 0.8354 - val_loss: 1.3321 - val_accuracy: 0.6766 - lr: 0.0100\n",
            "Epoch 30/250\n",
            "390/390 [==============================] - 89s 228ms/step - loss: 0.4612 - accuracy: 0.8392 - val_loss: 0.8776 - val_accuracy: 0.7475 - lr: 0.0100\n",
            "Epoch 31/250\n",
            "390/390 [==============================] - 89s 228ms/step - loss: 0.4449 - accuracy: 0.8458 - val_loss: 0.8911 - val_accuracy: 0.7552 - lr: 0.0100\n",
            "Epoch 32/250\n",
            "390/390 [==============================] - 89s 228ms/step - loss: 0.4419 - accuracy: 0.8449 - val_loss: 0.7168 - val_accuracy: 0.7979 - lr: 0.0100\n",
            "Epoch 33/250\n",
            "390/390 [==============================] - 89s 228ms/step - loss: 0.4303 - accuracy: 0.8489 - val_loss: 0.8216 - val_accuracy: 0.7626 - lr: 0.0100\n",
            "Epoch 34/250\n",
            "390/390 [==============================] - 89s 229ms/step - loss: 0.4211 - accuracy: 0.8520 - val_loss: 0.9377 - val_accuracy: 0.7548 - lr: 0.0100\n",
            "Epoch 35/250\n",
            "390/390 [==============================] - 89s 229ms/step - loss: 0.4196 - accuracy: 0.8527 - val_loss: 0.8878 - val_accuracy: 0.7491 - lr: 0.0100\n",
            "Epoch 36/250\n",
            "390/390 [==============================] - 90s 230ms/step - loss: 0.4069 - accuracy: 0.8583 - val_loss: 0.7068 - val_accuracy: 0.7959 - lr: 0.0100\n",
            "Epoch 37/250\n",
            "390/390 [==============================] - 89s 229ms/step - loss: 0.4033 - accuracy: 0.8585 - val_loss: 0.7892 - val_accuracy: 0.7760 - lr: 0.0100\n",
            "Epoch 38/250\n",
            "390/390 [==============================] - 89s 229ms/step - loss: 0.3947 - accuracy: 0.8596 - val_loss: 0.6583 - val_accuracy: 0.8122 - lr: 0.0100\n",
            "Epoch 39/250\n",
            "390/390 [==============================] - 89s 229ms/step - loss: 0.3902 - accuracy: 0.8643 - val_loss: 1.0943 - val_accuracy: 0.7339 - lr: 0.0100\n",
            "Epoch 40/250\n",
            "390/390 [==============================] - 89s 229ms/step - loss: 0.3839 - accuracy: 0.8653 - val_loss: 1.2868 - val_accuracy: 0.7035 - lr: 0.0100\n",
            "Epoch 41/250\n",
            "390/390 [==============================] - 89s 228ms/step - loss: 0.3780 - accuracy: 0.8672 - val_loss: 0.6945 - val_accuracy: 0.8041 - lr: 0.0100\n",
            "Epoch 42/250\n",
            "390/390 [==============================] - 89s 228ms/step - loss: 0.3680 - accuracy: 0.8723 - val_loss: 0.6306 - val_accuracy: 0.8192 - lr: 0.0100\n",
            "Epoch 43/250\n",
            "390/390 [==============================] - 89s 229ms/step - loss: 0.3715 - accuracy: 0.8709 - val_loss: 0.6368 - val_accuracy: 0.8149 - lr: 0.0100\n",
            "Epoch 44/250\n",
            "390/390 [==============================] - 90s 229ms/step - loss: 0.3572 - accuracy: 0.8740 - val_loss: 0.5664 - val_accuracy: 0.8312 - lr: 0.0100\n",
            "Epoch 45/250\n",
            "390/390 [==============================] - 90s 231ms/step - loss: 0.3498 - accuracy: 0.8766 - val_loss: 0.7877 - val_accuracy: 0.7932 - lr: 0.0100\n",
            "Epoch 46/250\n",
            "390/390 [==============================] - 90s 230ms/step - loss: 0.3480 - accuracy: 0.8770 - val_loss: 0.6831 - val_accuracy: 0.8077 - lr: 0.0100\n",
            "Epoch 47/250\n",
            "390/390 [==============================] - 90s 230ms/step - loss: 0.3499 - accuracy: 0.8771 - val_loss: 0.5764 - val_accuracy: 0.8262 - lr: 0.0100\n",
            "Epoch 48/250\n",
            "390/390 [==============================] - 90s 231ms/step - loss: 0.3398 - accuracy: 0.8811 - val_loss: 0.5899 - val_accuracy: 0.8302 - lr: 0.0100\n",
            "Epoch 49/250\n",
            "390/390 [==============================] - 90s 231ms/step - loss: 0.3333 - accuracy: 0.8824 - val_loss: 0.5046 - val_accuracy: 0.8430 - lr: 0.0100\n",
            "Epoch 50/250\n",
            "390/390 [==============================] - 89s 229ms/step - loss: 0.3285 - accuracy: 0.8836 - val_loss: 0.7470 - val_accuracy: 0.7983 - lr: 0.0100\n",
            "Epoch 51/250\n",
            "390/390 [==============================] - 89s 229ms/step - loss: 0.3308 - accuracy: 0.8835 - val_loss: 0.6771 - val_accuracy: 0.8132 - lr: 0.0100\n",
            "Epoch 52/250\n",
            "390/390 [==============================] - 89s 229ms/step - loss: 0.2831 - accuracy: 0.9003 - val_loss: 0.5249 - val_accuracy: 0.8457 - lr: 0.0050\n",
            "Epoch 53/250\n",
            "390/390 [==============================] - 89s 228ms/step - loss: 0.2690 - accuracy: 0.9053 - val_loss: 0.4922 - val_accuracy: 0.8558 - lr: 0.0050\n",
            "Epoch 54/250\n",
            "390/390 [==============================] - 90s 230ms/step - loss: 0.2706 - accuracy: 0.9048 - val_loss: 0.5132 - val_accuracy: 0.8464 - lr: 0.0050\n",
            "Epoch 55/250\n",
            "390/390 [==============================] - 90s 230ms/step - loss: 0.2662 - accuracy: 0.9051 - val_loss: 0.4435 - val_accuracy: 0.8605 - lr: 0.0050\n",
            "Epoch 56/250\n",
            "390/390 [==============================] - 90s 230ms/step - loss: 0.2592 - accuracy: 0.9065 - val_loss: 0.4853 - val_accuracy: 0.8546 - lr: 0.0050\n",
            "Epoch 57/250\n",
            "390/390 [==============================] - 90s 231ms/step - loss: 0.2570 - accuracy: 0.9102 - val_loss: 0.4314 - val_accuracy: 0.8703 - lr: 0.0050\n",
            "Epoch 58/250\n",
            "390/390 [==============================] - 89s 229ms/step - loss: 0.2545 - accuracy: 0.9098 - val_loss: 0.4437 - val_accuracy: 0.8636 - lr: 0.0050\n",
            "Epoch 59/250\n",
            "390/390 [==============================] - 89s 229ms/step - loss: 0.2550 - accuracy: 0.9098 - val_loss: 0.4078 - val_accuracy: 0.8773 - lr: 0.0050\n",
            "Epoch 60/250\n",
            "390/390 [==============================] - 90s 231ms/step - loss: 0.2516 - accuracy: 0.9117 - val_loss: 0.4228 - val_accuracy: 0.8700 - lr: 0.0050\n",
            "Epoch 61/250\n",
            "390/390 [==============================] - 89s 229ms/step - loss: 0.2462 - accuracy: 0.9119 - val_loss: 0.4232 - val_accuracy: 0.8713 - lr: 0.0050\n",
            "Epoch 62/250\n",
            "390/390 [==============================] - 89s 229ms/step - loss: 0.2470 - accuracy: 0.9132 - val_loss: 0.5515 - val_accuracy: 0.8412 - lr: 0.0050\n",
            "Epoch 63/250\n",
            "390/390 [==============================] - 90s 230ms/step - loss: 0.2405 - accuracy: 0.9139 - val_loss: 0.4385 - val_accuracy: 0.8658 - lr: 0.0050\n",
            "Epoch 64/250\n",
            "390/390 [==============================] - 90s 232ms/step - loss: 0.2454 - accuracy: 0.9137 - val_loss: 0.4727 - val_accuracy: 0.8618 - lr: 0.0050\n",
            "Epoch 65/250\n",
            "390/390 [==============================] - 89s 228ms/step - loss: 0.2363 - accuracy: 0.9157 - val_loss: 0.4362 - val_accuracy: 0.8684 - lr: 0.0050\n",
            "Epoch 66/250\n",
            "390/390 [==============================] - 89s 229ms/step - loss: 0.2351 - accuracy: 0.9158 - val_loss: 0.4068 - val_accuracy: 0.8759 - lr: 0.0050\n",
            "Epoch 67/250\n",
            "390/390 [==============================] - 89s 229ms/step - loss: 0.2341 - accuracy: 0.9172 - val_loss: 0.4263 - val_accuracy: 0.8746 - lr: 0.0050\n",
            "Epoch 68/250\n",
            "390/390 [==============================] - 89s 229ms/step - loss: 0.2313 - accuracy: 0.9170 - val_loss: 0.4137 - val_accuracy: 0.8748 - lr: 0.0050\n",
            "Epoch 69/250\n",
            "390/390 [==============================] - 89s 229ms/step - loss: 0.2306 - accuracy: 0.9177 - val_loss: 0.4200 - val_accuracy: 0.8733 - lr: 0.0050\n",
            "Epoch 70/250\n",
            "390/390 [==============================] - 89s 229ms/step - loss: 0.2293 - accuracy: 0.9170 - val_loss: 0.4282 - val_accuracy: 0.8749 - lr: 0.0050\n",
            "Epoch 71/250\n",
            "390/390 [==============================] - 90s 230ms/step - loss: 0.2310 - accuracy: 0.9188 - val_loss: 0.4166 - val_accuracy: 0.8751 - lr: 0.0050\n",
            "Epoch 72/250\n",
            "390/390 [==============================] - 89s 229ms/step - loss: 0.2211 - accuracy: 0.9209 - val_loss: 0.4725 - val_accuracy: 0.8683 - lr: 0.0050\n",
            "Epoch 73/250\n",
            "390/390 [==============================] - 90s 230ms/step - loss: 0.2198 - accuracy: 0.9224 - val_loss: 0.4320 - val_accuracy: 0.8721 - lr: 0.0050\n",
            "Epoch 74/250\n",
            "390/390 [==============================] - 89s 229ms/step - loss: 0.2263 - accuracy: 0.9202 - val_loss: 0.4442 - val_accuracy: 0.8680 - lr: 0.0050\n",
            "Epoch 75/250\n",
            "390/390 [==============================] - 89s 229ms/step - loss: 0.2208 - accuracy: 0.9223 - val_loss: 0.4641 - val_accuracy: 0.8661 - lr: 0.0050\n",
            "Epoch 76/250\n",
            "390/390 [==============================] - 89s 229ms/step - loss: 0.2145 - accuracy: 0.9226 - val_loss: 0.5191 - val_accuracy: 0.8576 - lr: 0.0050\n",
            "Epoch 77/250\n",
            "390/390 [==============================] - 89s 229ms/step - loss: 0.2163 - accuracy: 0.9227 - val_loss: 0.3948 - val_accuracy: 0.8860 - lr: 0.0050\n",
            "Epoch 78/250\n",
            "390/390 [==============================] - 89s 229ms/step - loss: 0.2148 - accuracy: 0.9230 - val_loss: 0.4994 - val_accuracy: 0.8618 - lr: 0.0050\n",
            "Epoch 79/250\n",
            "390/390 [==============================] - 89s 229ms/step - loss: 0.2113 - accuracy: 0.9236 - val_loss: 0.4470 - val_accuracy: 0.8728 - lr: 0.0050\n",
            "Epoch 80/250\n",
            "390/390 [==============================] - 89s 229ms/step - loss: 0.2119 - accuracy: 0.9243 - val_loss: 0.5240 - val_accuracy: 0.8533 - lr: 0.0050\n",
            "Epoch 81/250\n",
            "390/390 [==============================] - 89s 228ms/step - loss: 0.2063 - accuracy: 0.9259 - val_loss: 0.4823 - val_accuracy: 0.8676 - lr: 0.0050\n",
            "Epoch 82/250\n",
            "390/390 [==============================] - 90s 230ms/step - loss: 0.1846 - accuracy: 0.9347 - val_loss: 0.3669 - val_accuracy: 0.8919 - lr: 0.0010\n",
            "Epoch 83/250\n",
            "390/390 [==============================] - 89s 229ms/step - loss: 0.1690 - accuracy: 0.9400 - val_loss: 0.3734 - val_accuracy: 0.8899 - lr: 0.0010\n",
            "Epoch 84/250\n",
            "390/390 [==============================] - 89s 229ms/step - loss: 0.1664 - accuracy: 0.9409 - val_loss: 0.3777 - val_accuracy: 0.8896 - lr: 0.0010\n",
            "Epoch 85/250\n",
            "390/390 [==============================] - 89s 229ms/step - loss: 0.1654 - accuracy: 0.9410 - val_loss: 0.3797 - val_accuracy: 0.8871 - lr: 0.0010\n",
            "Epoch 86/250\n",
            "390/390 [==============================] - 89s 229ms/step - loss: 0.1654 - accuracy: 0.9410 - val_loss: 0.3797 - val_accuracy: 0.8875 - lr: 0.0010\n",
            "Epoch 87/250\n",
            "390/390 [==============================] - 90s 230ms/step - loss: 0.1605 - accuracy: 0.9430 - val_loss: 0.3769 - val_accuracy: 0.8886 - lr: 0.0010\n",
            "Epoch 88/250\n",
            "390/390 [==============================] - 89s 229ms/step - loss: 0.1588 - accuracy: 0.9423 - val_loss: 0.4040 - val_accuracy: 0.8847 - lr: 0.0010\n",
            "Epoch 89/250\n",
            "390/390 [==============================] - 89s 229ms/step - loss: 0.1587 - accuracy: 0.9436 - val_loss: 0.3937 - val_accuracy: 0.8885 - lr: 0.0010\n",
            "Epoch 90/250\n",
            "390/390 [==============================] - 89s 229ms/step - loss: 0.1566 - accuracy: 0.9450 - val_loss: 0.3843 - val_accuracy: 0.8903 - lr: 0.0010\n",
            "Epoch 91/250\n",
            "390/390 [==============================] - 89s 229ms/step - loss: 0.1572 - accuracy: 0.9435 - val_loss: 0.3826 - val_accuracy: 0.8880 - lr: 0.0010\n",
            "Epoch 92/250\n",
            "390/390 [==============================] - 89s 229ms/step - loss: 0.1578 - accuracy: 0.9440 - val_loss: 0.3841 - val_accuracy: 0.8879 - lr: 0.0010\n",
            "Epoch 93/250\n",
            "390/390 [==============================] - 89s 229ms/step - loss: 0.1555 - accuracy: 0.9439 - val_loss: 0.3918 - val_accuracy: 0.8883 - lr: 0.0010\n",
            "Epoch 94/250\n",
            "390/390 [==============================] - 89s 228ms/step - loss: 0.1532 - accuracy: 0.9447 - val_loss: 0.3899 - val_accuracy: 0.8891 - lr: 0.0010\n",
            "Epoch 95/250\n",
            "390/390 [==============================] - 89s 228ms/step - loss: 0.1547 - accuracy: 0.9458 - val_loss: 0.3850 - val_accuracy: 0.8898 - lr: 0.0010\n",
            "Epoch 96/250\n",
            "390/390 [==============================] - 89s 229ms/step - loss: 0.1508 - accuracy: 0.9454 - val_loss: 0.3920 - val_accuracy: 0.8903 - lr: 0.0010\n",
            "Epoch 97/250\n",
            "390/390 [==============================] - 89s 228ms/step - loss: 0.1482 - accuracy: 0.9469 - val_loss: 0.3946 - val_accuracy: 0.8909 - lr: 0.0010\n",
            "Epoch 98/250\n",
            "390/390 [==============================] - 89s 228ms/step - loss: 0.1507 - accuracy: 0.9461 - val_loss: 0.3806 - val_accuracy: 0.8913 - lr: 0.0010\n",
            "Epoch 99/250\n",
            "390/390 [==============================] - 89s 228ms/step - loss: 0.1497 - accuracy: 0.9468 - val_loss: 0.4026 - val_accuracy: 0.8870 - lr: 0.0010\n",
            "Epoch 100/250\n",
            "390/390 [==============================] - 89s 228ms/step - loss: 0.1474 - accuracy: 0.9476 - val_loss: 0.4008 - val_accuracy: 0.8880 - lr: 0.0010\n",
            "Epoch 101/250\n",
            "390/390 [==============================] - 89s 228ms/step - loss: 0.1478 - accuracy: 0.9477 - val_loss: 0.3918 - val_accuracy: 0.8900 - lr: 0.0010\n",
            "Epoch 102/250\n",
            "390/390 [==============================] - 89s 228ms/step - loss: 0.1489 - accuracy: 0.9461 - val_loss: 0.4121 - val_accuracy: 0.8879 - lr: 0.0010\n",
            "Epoch 103/250\n",
            "390/390 [==============================] - 89s 229ms/step - loss: 0.1456 - accuracy: 0.9488 - val_loss: 0.3982 - val_accuracy: 0.8911 - lr: 0.0010\n",
            "Epoch 104/250\n",
            "390/390 [==============================] - 89s 229ms/step - loss: 0.1444 - accuracy: 0.9490 - val_loss: 0.3915 - val_accuracy: 0.8895 - lr: 0.0010\n",
            "Epoch 105/250\n",
            "390/390 [==============================] - 89s 229ms/step - loss: 0.1460 - accuracy: 0.9474 - val_loss: 0.4109 - val_accuracy: 0.8889 - lr: 0.0010\n",
            "Epoch 106/250\n",
            "390/390 [==============================] - 89s 229ms/step - loss: 0.1484 - accuracy: 0.9466 - val_loss: 0.3941 - val_accuracy: 0.8914 - lr: 0.0010\n",
            "Epoch 107/250\n",
            "390/390 [==============================] - 89s 228ms/step - loss: 0.1417 - accuracy: 0.9484 - val_loss: 0.4013 - val_accuracy: 0.8906 - lr: 0.0010\n",
            "Epoch 108/250\n",
            "390/390 [==============================] - 89s 229ms/step - loss: 0.1441 - accuracy: 0.9482 - val_loss: 0.4156 - val_accuracy: 0.8855 - lr: 0.0010\n",
            "Epoch 109/250\n",
            "390/390 [==============================] - 89s 228ms/step - loss: 0.1418 - accuracy: 0.9490 - val_loss: 0.4106 - val_accuracy: 0.8877 - lr: 0.0010\n",
            "Epoch 110/250\n",
            "390/390 [==============================] - 89s 229ms/step - loss: 0.1426 - accuracy: 0.9484 - val_loss: 0.4096 - val_accuracy: 0.8889 - lr: 0.0010\n",
            "Epoch 111/250\n",
            "390/390 [==============================] - 89s 229ms/step - loss: 0.1423 - accuracy: 0.9489 - val_loss: 0.3956 - val_accuracy: 0.8914 - lr: 0.0010\n",
            "Epoch 112/250\n",
            "390/390 [==============================] - 89s 228ms/step - loss: 0.1431 - accuracy: 0.9474 - val_loss: 0.4091 - val_accuracy: 0.8877 - lr: 0.0010\n",
            "Epoch 113/250\n",
            "390/390 [==============================] - 89s 229ms/step - loss: 0.1408 - accuracy: 0.9502 - val_loss: 0.4118 - val_accuracy: 0.8889 - lr: 0.0010\n",
            "Epoch 114/250\n",
            "390/390 [==============================] - 89s 229ms/step - loss: 0.1383 - accuracy: 0.9500 - val_loss: 0.4092 - val_accuracy: 0.8882 - lr: 0.0010\n",
            "Epoch 115/250\n",
            "390/390 [==============================] - 89s 229ms/step - loss: 0.1404 - accuracy: 0.9486 - val_loss: 0.4107 - val_accuracy: 0.8868 - lr: 0.0010\n",
            "Epoch 116/250\n",
            "390/390 [==============================] - 89s 229ms/step - loss: 0.1381 - accuracy: 0.9500 - val_loss: 0.4016 - val_accuracy: 0.8879 - lr: 0.0010\n",
            "Epoch 117/250\n",
            "390/390 [==============================] - 89s 229ms/step - loss: 0.1388 - accuracy: 0.9506 - val_loss: 0.4032 - val_accuracy: 0.8886 - lr: 0.0010\n",
            "Epoch 118/250\n",
            "390/390 [==============================] - 89s 229ms/step - loss: 0.1400 - accuracy: 0.9507 - val_loss: 0.4067 - val_accuracy: 0.8870 - lr: 0.0010\n",
            "Epoch 119/250\n",
            "390/390 [==============================] - 89s 228ms/step - loss: 0.1332 - accuracy: 0.9528 - val_loss: 0.4079 - val_accuracy: 0.8886 - lr: 0.0010\n",
            "Epoch 120/250\n",
            "390/390 [==============================] - 89s 228ms/step - loss: 0.1333 - accuracy: 0.9524 - val_loss: 0.4247 - val_accuracy: 0.8870 - lr: 0.0010\n",
            "Epoch 121/250\n",
            "390/390 [==============================] - 89s 229ms/step - loss: 0.1344 - accuracy: 0.9520 - val_loss: 0.4053 - val_accuracy: 0.8894 - lr: 0.0010\n",
            "Epoch 122/250\n",
            "390/390 [==============================] - 89s 229ms/step - loss: 0.1332 - accuracy: 0.9520 - val_loss: 0.4150 - val_accuracy: 0.8857 - lr: 0.0010\n",
            "Epoch 123/250\n",
            "390/390 [==============================] - 89s 229ms/step - loss: 0.1357 - accuracy: 0.9505 - val_loss: 0.4234 - val_accuracy: 0.8866 - lr: 0.0010\n",
            "Epoch 124/250\n",
            "390/390 [==============================] - 89s 229ms/step - loss: 0.1342 - accuracy: 0.9517 - val_loss: 0.4128 - val_accuracy: 0.8886 - lr: 0.0010\n",
            "Epoch 125/250\n",
            "390/390 [==============================] - 89s 229ms/step - loss: 0.1353 - accuracy: 0.9524 - val_loss: 0.3969 - val_accuracy: 0.8918 - lr: 0.0010\n",
            "Epoch 126/250\n",
            "390/390 [==============================] - 93s 238ms/step - loss: 0.1348 - accuracy: 0.9509 - val_loss: 0.4277 - val_accuracy: 0.8861 - lr: 0.0010\n",
            "Epoch 127/250\n",
            "390/390 [==============================] - 90s 231ms/step - loss: 0.1327 - accuracy: 0.9531 - val_loss: 0.3976 - val_accuracy: 0.8891 - lr: 0.0010\n",
            "Epoch 128/250\n",
            "390/390 [==============================] - 90s 231ms/step - loss: 0.1303 - accuracy: 0.9524 - val_loss: 0.4014 - val_accuracy: 0.8896 - lr: 0.0010\n",
            "Epoch 129/250\n",
            "390/390 [==============================] - 90s 230ms/step - loss: 0.1348 - accuracy: 0.9520 - val_loss: 0.4306 - val_accuracy: 0.8864 - lr: 0.0010\n",
            "Epoch 130/250\n",
            "390/390 [==============================] - 90s 230ms/step - loss: 0.1306 - accuracy: 0.9533 - val_loss: 0.4193 - val_accuracy: 0.8852 - lr: 0.0010\n",
            "Epoch 131/250\n",
            "390/390 [==============================] - 90s 230ms/step - loss: 0.1326 - accuracy: 0.9529 - val_loss: 0.4107 - val_accuracy: 0.8903 - lr: 0.0010\n",
            "Epoch 132/250\n",
            "390/390 [==============================] - 89s 229ms/step - loss: 0.1299 - accuracy: 0.9535 - val_loss: 0.4061 - val_accuracy: 0.8926 - lr: 0.0010\n",
            "Epoch 133/250\n",
            "390/390 [==============================] - 90s 230ms/step - loss: 0.1318 - accuracy: 0.9521 - val_loss: 0.4231 - val_accuracy: 0.8872 - lr: 0.0010\n",
            "Epoch 134/250\n",
            "390/390 [==============================] - 89s 229ms/step - loss: 0.1288 - accuracy: 0.9534 - val_loss: 0.4089 - val_accuracy: 0.8918 - lr: 0.0010\n",
            "Epoch 135/250\n",
            "390/390 [==============================] - 89s 229ms/step - loss: 0.1307 - accuracy: 0.9536 - val_loss: 0.4195 - val_accuracy: 0.8908 - lr: 0.0010\n",
            "Epoch 136/250\n",
            "390/390 [==============================] - 89s 229ms/step - loss: 0.1335 - accuracy: 0.9516 - val_loss: 0.4172 - val_accuracy: 0.8876 - lr: 0.0010\n",
            "Epoch 137/250\n",
            "390/390 [==============================] - 89s 229ms/step - loss: 0.1270 - accuracy: 0.9545 - val_loss: 0.4203 - val_accuracy: 0.8874 - lr: 0.0010\n",
            "Epoch 138/250\n",
            "390/390 [==============================] - 89s 228ms/step - loss: 0.1273 - accuracy: 0.9550 - val_loss: 0.4219 - val_accuracy: 0.8864 - lr: 0.0010\n",
            "Epoch 139/250\n",
            "390/390 [==============================] - 89s 229ms/step - loss: 0.1340 - accuracy: 0.9526 - val_loss: 0.4034 - val_accuracy: 0.8924 - lr: 0.0010\n",
            "Epoch 140/250\n",
            "390/390 [==============================] - 90s 230ms/step - loss: 0.1244 - accuracy: 0.9553 - val_loss: 0.4249 - val_accuracy: 0.8889 - lr: 0.0010\n",
            "Epoch 141/250\n",
            "390/390 [==============================] - 89s 229ms/step - loss: 0.1275 - accuracy: 0.9550 - val_loss: 0.4145 - val_accuracy: 0.8907 - lr: 0.0010\n",
            "Epoch 142/250\n",
            "390/390 [==============================] - 89s 229ms/step - loss: 0.1273 - accuracy: 0.9539 - val_loss: 0.4076 - val_accuracy: 0.8891 - lr: 0.0010\n",
            "Epoch 143/250\n",
            "390/390 [==============================] - 89s 229ms/step - loss: 0.1266 - accuracy: 0.9542 - val_loss: 0.3980 - val_accuracy: 0.8910 - lr: 0.0010\n",
            "Epoch 144/250\n",
            "390/390 [==============================] - 89s 229ms/step - loss: 0.1307 - accuracy: 0.9528 - val_loss: 0.4131 - val_accuracy: 0.8888 - lr: 0.0010\n",
            "Epoch 145/250\n",
            "390/390 [==============================] - 89s 229ms/step - loss: 0.1277 - accuracy: 0.9539 - val_loss: 0.4159 - val_accuracy: 0.8885 - lr: 0.0010\n",
            "Epoch 146/250\n",
            "390/390 [==============================] - 89s 229ms/step - loss: 0.1227 - accuracy: 0.9551 - val_loss: 0.3976 - val_accuracy: 0.8929 - lr: 0.0010\n",
            "Epoch 147/250\n",
            "390/390 [==============================] - 89s 229ms/step - loss: 0.1265 - accuracy: 0.9539 - val_loss: 0.3990 - val_accuracy: 0.8917 - lr: 0.0010\n",
            "Epoch 148/250\n",
            "390/390 [==============================] - 89s 229ms/step - loss: 0.1284 - accuracy: 0.9538 - val_loss: 0.4122 - val_accuracy: 0.8910 - lr: 0.0010\n",
            "Epoch 149/250\n",
            "390/390 [==============================] - 89s 229ms/step - loss: 0.1257 - accuracy: 0.9553 - val_loss: 0.4191 - val_accuracy: 0.8889 - lr: 0.0010\n",
            "Epoch 150/250\n",
            "390/390 [==============================] - 89s 229ms/step - loss: 0.1216 - accuracy: 0.9558 - val_loss: 0.4197 - val_accuracy: 0.8890 - lr: 0.0010\n",
            "Epoch 151/250\n",
            "390/390 [==============================] - 89s 229ms/step - loss: 0.1254 - accuracy: 0.9559 - val_loss: 0.4158 - val_accuracy: 0.8891 - lr: 0.0010\n",
            "Epoch 152/250\n",
            "390/390 [==============================] - 89s 229ms/step - loss: 0.1213 - accuracy: 0.9564 - val_loss: 0.4173 - val_accuracy: 0.8902 - lr: 0.0010\n",
            "Epoch 153/250\n",
            "390/390 [==============================] - 89s 229ms/step - loss: 0.1201 - accuracy: 0.9567 - val_loss: 0.4440 - val_accuracy: 0.8843 - lr: 0.0010\n",
            "Epoch 154/250\n",
            "390/390 [==============================] - 89s 228ms/step - loss: 0.1216 - accuracy: 0.9575 - val_loss: 0.4190 - val_accuracy: 0.8885 - lr: 0.0010\n",
            "Epoch 155/250\n",
            "390/390 [==============================] - 89s 228ms/step - loss: 0.1208 - accuracy: 0.9568 - val_loss: 0.4200 - val_accuracy: 0.8894 - lr: 0.0010\n",
            "Epoch 156/250\n",
            "390/390 [==============================] - 89s 228ms/step - loss: 0.1220 - accuracy: 0.9556 - val_loss: 0.4158 - val_accuracy: 0.8923 - lr: 0.0010\n",
            "Epoch 157/250\n",
            "390/390 [==============================] - 89s 228ms/step - loss: 0.1283 - accuracy: 0.9537 - val_loss: 0.4152 - val_accuracy: 0.8903 - lr: 0.0010\n",
            "Epoch 158/250\n",
            "390/390 [==============================] - 89s 229ms/step - loss: 0.1228 - accuracy: 0.9558 - val_loss: 0.4238 - val_accuracy: 0.8896 - lr: 0.0010\n",
            "Epoch 159/250\n",
            "390/390 [==============================] - 89s 229ms/step - loss: 0.1221 - accuracy: 0.9564 - val_loss: 0.4138 - val_accuracy: 0.8923 - lr: 0.0010\n",
            "Epoch 160/250\n",
            "390/390 [==============================] - 89s 229ms/step - loss: 0.1183 - accuracy: 0.9580 - val_loss: 0.4161 - val_accuracy: 0.8900 - lr: 0.0010\n",
            "Epoch 161/250\n",
            "390/390 [==============================] - 89s 229ms/step - loss: 0.1216 - accuracy: 0.9570 - val_loss: 0.4235 - val_accuracy: 0.8907 - lr: 0.0010\n",
            "Epoch 162/250\n",
            "390/390 [==============================] - 89s 229ms/step - loss: 0.1214 - accuracy: 0.9558 - val_loss: 0.4231 - val_accuracy: 0.8894 - lr: 0.0010\n",
            "Epoch 163/250\n",
            "390/390 [==============================] - 89s 229ms/step - loss: 0.1179 - accuracy: 0.9580 - val_loss: 0.4027 - val_accuracy: 0.8959 - lr: 0.0010\n",
            "Epoch 164/250\n",
            "390/390 [==============================] - 90s 230ms/step - loss: 0.1193 - accuracy: 0.9574 - val_loss: 0.4405 - val_accuracy: 0.8877 - lr: 0.0010\n",
            "Epoch 165/250\n",
            "390/390 [==============================] - 89s 229ms/step - loss: 0.1184 - accuracy: 0.9576 - val_loss: 0.4182 - val_accuracy: 0.8920 - lr: 0.0010\n",
            "Epoch 166/250\n",
            "390/390 [==============================] - 89s 229ms/step - loss: 0.1181 - accuracy: 0.9583 - val_loss: 0.4125 - val_accuracy: 0.8927 - lr: 0.0010\n",
            "Epoch 167/250\n",
            "390/390 [==============================] - 89s 228ms/step - loss: 0.1192 - accuracy: 0.9567 - val_loss: 0.4149 - val_accuracy: 0.8909 - lr: 0.0010\n",
            "Epoch 168/250\n",
            "390/390 [==============================] - 90s 230ms/step - loss: 0.1199 - accuracy: 0.9575 - val_loss: 0.4242 - val_accuracy: 0.8904 - lr: 0.0010\n",
            "Epoch 169/250\n",
            "390/390 [==============================] - 89s 228ms/step - loss: 0.1181 - accuracy: 0.9584 - val_loss: 0.4193 - val_accuracy: 0.8897 - lr: 0.0010\n",
            "Epoch 170/250\n",
            "390/390 [==============================] - 89s 228ms/step - loss: 0.1184 - accuracy: 0.9567 - val_loss: 0.4182 - val_accuracy: 0.8908 - lr: 0.0010\n",
            "Epoch 171/250\n",
            "390/390 [==============================] - 89s 229ms/step - loss: 0.1181 - accuracy: 0.9583 - val_loss: 0.4264 - val_accuracy: 0.8922 - lr: 0.0010\n",
            "Epoch 172/250\n",
            "390/390 [==============================] - 89s 228ms/step - loss: 0.1164 - accuracy: 0.9577 - val_loss: 0.4454 - val_accuracy: 0.8875 - lr: 0.0010\n",
            "Epoch 173/250\n",
            "390/390 [==============================] - 89s 229ms/step - loss: 0.1135 - accuracy: 0.9601 - val_loss: 0.4349 - val_accuracy: 0.8868 - lr: 0.0010\n",
            "Epoch 174/250\n",
            "390/390 [==============================] - 89s 228ms/step - loss: 0.1159 - accuracy: 0.9577 - val_loss: 0.4425 - val_accuracy: 0.8859 - lr: 0.0010\n",
            "Epoch 175/250\n",
            "390/390 [==============================] - 89s 228ms/step - loss: 0.1158 - accuracy: 0.9582 - val_loss: 0.4148 - val_accuracy: 0.8901 - lr: 0.0010\n",
            "Epoch 176/250\n",
            "390/390 [==============================] - 90s 229ms/step - loss: 0.1145 - accuracy: 0.9591 - val_loss: 0.4411 - val_accuracy: 0.8856 - lr: 0.0010\n",
            "Epoch 177/250\n",
            "390/390 [==============================] - 89s 229ms/step - loss: 0.1180 - accuracy: 0.9562 - val_loss: 0.4412 - val_accuracy: 0.8862 - lr: 0.0010\n",
            "Epoch 178/250\n",
            "390/390 [==============================] - 90s 232ms/step - loss: 0.1188 - accuracy: 0.9574 - val_loss: 0.4185 - val_accuracy: 0.8917 - lr: 0.0010\n",
            "Epoch 179/250\n",
            "390/390 [==============================] - 89s 229ms/step - loss: 0.1119 - accuracy: 0.9605 - val_loss: 0.4255 - val_accuracy: 0.8914 - lr: 0.0010\n",
            "Epoch 180/250\n",
            "390/390 [==============================] - 89s 228ms/step - loss: 0.1114 - accuracy: 0.9596 - val_loss: 0.4109 - val_accuracy: 0.8922 - lr: 0.0010\n",
            "Epoch 181/250\n",
            "390/390 [==============================] - 89s 229ms/step - loss: 0.1137 - accuracy: 0.9595 - val_loss: 0.4298 - val_accuracy: 0.8874 - lr: 0.0010\n",
            "Epoch 182/250\n",
            "390/390 [==============================] - 89s 229ms/step - loss: 0.1145 - accuracy: 0.9589 - val_loss: 0.4211 - val_accuracy: 0.8908 - lr: 0.0010\n",
            "Epoch 183/250\n",
            "390/390 [==============================] - 89s 229ms/step - loss: 0.1136 - accuracy: 0.9597 - val_loss: 0.4294 - val_accuracy: 0.8890 - lr: 0.0010\n",
            "Epoch 184/250\n",
            "390/390 [==============================] - 89s 229ms/step - loss: 0.1125 - accuracy: 0.9585 - val_loss: 0.4477 - val_accuracy: 0.8867 - lr: 0.0010\n",
            "Epoch 185/250\n",
            "390/390 [==============================] - 89s 229ms/step - loss: 0.1120 - accuracy: 0.9598 - val_loss: 0.4391 - val_accuracy: 0.8870 - lr: 0.0010\n",
            "Epoch 186/250\n",
            "390/390 [==============================] - 89s 229ms/step - loss: 0.1143 - accuracy: 0.9591 - val_loss: 0.4389 - val_accuracy: 0.8880 - lr: 0.0010\n",
            "Epoch 187/250\n",
            "390/390 [==============================] - 89s 229ms/step - loss: 0.1124 - accuracy: 0.9599 - val_loss: 0.4367 - val_accuracy: 0.8885 - lr: 0.0010\n",
            "Epoch 188/250\n",
            "390/390 [==============================] - 89s 229ms/step - loss: 0.1089 - accuracy: 0.9604 - val_loss: 0.4349 - val_accuracy: 0.8893 - lr: 0.0010\n",
            "Epoch 189/250\n",
            "390/390 [==============================] - 89s 229ms/step - loss: 0.1105 - accuracy: 0.9605 - val_loss: 0.4082 - val_accuracy: 0.8931 - lr: 0.0010\n",
            "Epoch 190/250\n",
            "390/390 [==============================] - 89s 229ms/step - loss: 0.1100 - accuracy: 0.9599 - val_loss: 0.4428 - val_accuracy: 0.8897 - lr: 0.0010\n",
            "Epoch 191/250\n",
            "390/390 [==============================] - 89s 229ms/step - loss: 0.1083 - accuracy: 0.9612 - val_loss: 0.4394 - val_accuracy: 0.8880 - lr: 0.0010\n",
            "Epoch 192/250\n",
            "390/390 [==============================] - 90s 230ms/step - loss: 0.1127 - accuracy: 0.9585 - val_loss: 0.4231 - val_accuracy: 0.8923 - lr: 0.0010\n",
            "Epoch 193/250\n",
            "390/390 [==============================] - 89s 229ms/step - loss: 0.1109 - accuracy: 0.9610 - val_loss: 0.4276 - val_accuracy: 0.8901 - lr: 0.0010\n",
            "Epoch 194/250\n",
            "390/390 [==============================] - 89s 229ms/step - loss: 0.1074 - accuracy: 0.9613 - val_loss: 0.4362 - val_accuracy: 0.8879 - lr: 0.0010\n",
            "Epoch 195/250\n",
            "390/390 [==============================] - 89s 229ms/step - loss: 0.1057 - accuracy: 0.9620 - val_loss: 0.4410 - val_accuracy: 0.8886 - lr: 0.0010\n",
            "Epoch 196/250\n",
            "390/390 [==============================] - 89s 229ms/step - loss: 0.1126 - accuracy: 0.9595 - val_loss: 0.4292 - val_accuracy: 0.8902 - lr: 0.0010\n",
            "Epoch 197/250\n",
            "390/390 [==============================] - 89s 229ms/step - loss: 0.1090 - accuracy: 0.9613 - val_loss: 0.4389 - val_accuracy: 0.8880 - lr: 0.0010\n",
            "Epoch 198/250\n",
            "390/390 [==============================] - 89s 228ms/step - loss: 0.1075 - accuracy: 0.9613 - val_loss: 0.4331 - val_accuracy: 0.8910 - lr: 0.0010\n",
            "Epoch 199/250\n",
            "390/390 [==============================] - 89s 229ms/step - loss: 0.1081 - accuracy: 0.9605 - val_loss: 0.4333 - val_accuracy: 0.8928 - lr: 0.0010\n",
            "Epoch 200/250\n",
            "390/390 [==============================] - 89s 229ms/step - loss: 0.1082 - accuracy: 0.9613 - val_loss: 0.4351 - val_accuracy: 0.8890 - lr: 0.0010\n",
            "Epoch 201/250\n",
            "390/390 [==============================] - 89s 229ms/step - loss: 0.1063 - accuracy: 0.9621 - val_loss: 0.4402 - val_accuracy: 0.8900 - lr: 0.0010\n",
            "Epoch 202/250\n",
            "390/390 [==============================] - 89s 229ms/step - loss: 0.1005 - accuracy: 0.9644 - val_loss: 0.4305 - val_accuracy: 0.8915 - lr: 1.0000e-04\n",
            "Epoch 203/250\n",
            "390/390 [==============================] - 89s 229ms/step - loss: 0.0983 - accuracy: 0.9647 - val_loss: 0.4295 - val_accuracy: 0.8917 - lr: 1.0000e-04\n",
            "Epoch 204/250\n",
            "390/390 [==============================] - 89s 229ms/step - loss: 0.1028 - accuracy: 0.9627 - val_loss: 0.4299 - val_accuracy: 0.8910 - lr: 1.0000e-04\n",
            "Epoch 205/250\n",
            "390/390 [==============================] - 90s 229ms/step - loss: 0.1012 - accuracy: 0.9632 - val_loss: 0.4286 - val_accuracy: 0.8907 - lr: 1.0000e-04\n",
            "Epoch 206/250\n",
            "390/390 [==============================] - 89s 229ms/step - loss: 0.0998 - accuracy: 0.9639 - val_loss: 0.4289 - val_accuracy: 0.8908 - lr: 1.0000e-04\n",
            "Epoch 207/250\n",
            "390/390 [==============================] - 89s 229ms/step - loss: 0.0947 - accuracy: 0.9663 - val_loss: 0.4261 - val_accuracy: 0.8914 - lr: 1.0000e-04\n",
            "Epoch 208/250\n",
            "390/390 [==============================] - 89s 229ms/step - loss: 0.0969 - accuracy: 0.9656 - val_loss: 0.4258 - val_accuracy: 0.8915 - lr: 1.0000e-04\n",
            "Epoch 209/250\n",
            "390/390 [==============================] - 89s 228ms/step - loss: 0.0989 - accuracy: 0.9648 - val_loss: 0.4235 - val_accuracy: 0.8915 - lr: 1.0000e-04\n",
            "Epoch 210/250\n",
            "390/390 [==============================] - 89s 229ms/step - loss: 0.1002 - accuracy: 0.9641 - val_loss: 0.4253 - val_accuracy: 0.8908 - lr: 1.0000e-04\n",
            "Epoch 211/250\n",
            "390/390 [==============================] - 89s 229ms/step - loss: 0.0973 - accuracy: 0.9648 - val_loss: 0.4219 - val_accuracy: 0.8924 - lr: 1.0000e-04\n",
            "Epoch 212/250\n",
            "390/390 [==============================] - 90s 230ms/step - loss: 0.0981 - accuracy: 0.9655 - val_loss: 0.4263 - val_accuracy: 0.8911 - lr: 1.0000e-04\n",
            "Epoch 213/250\n",
            "390/390 [==============================] - 89s 229ms/step - loss: 0.0947 - accuracy: 0.9662 - val_loss: 0.4298 - val_accuracy: 0.8907 - lr: 1.0000e-04\n",
            "Epoch 214/250\n",
            "390/390 [==============================] - 89s 229ms/step - loss: 0.0981 - accuracy: 0.9641 - val_loss: 0.4281 - val_accuracy: 0.8914 - lr: 1.0000e-04\n",
            "Epoch 215/250\n",
            "390/390 [==============================] - 89s 229ms/step - loss: 0.0957 - accuracy: 0.9655 - val_loss: 0.4276 - val_accuracy: 0.8914 - lr: 1.0000e-04\n",
            "Epoch 216/250\n",
            "390/390 [==============================] - 90s 230ms/step - loss: 0.0997 - accuracy: 0.9647 - val_loss: 0.4263 - val_accuracy: 0.8913 - lr: 1.0000e-04\n",
            "Epoch 217/250\n",
            "390/390 [==============================] - 89s 229ms/step - loss: 0.0971 - accuracy: 0.9653 - val_loss: 0.4270 - val_accuracy: 0.8912 - lr: 1.0000e-04\n",
            "Epoch 218/250\n",
            "390/390 [==============================] - 90s 231ms/step - loss: 0.0968 - accuracy: 0.9649 - val_loss: 0.4240 - val_accuracy: 0.8921 - lr: 1.0000e-04\n",
            "Epoch 219/250\n",
            "390/390 [==============================] - 90s 230ms/step - loss: 0.0957 - accuracy: 0.9664 - val_loss: 0.4254 - val_accuracy: 0.8917 - lr: 1.0000e-04\n",
            "Epoch 220/250\n",
            "390/390 [==============================] - 89s 229ms/step - loss: 0.0969 - accuracy: 0.9653 - val_loss: 0.4264 - val_accuracy: 0.8916 - lr: 1.0000e-04\n",
            "Epoch 221/250\n",
            "390/390 [==============================] - 89s 229ms/step - loss: 0.0960 - accuracy: 0.9652 - val_loss: 0.4257 - val_accuracy: 0.8917 - lr: 1.0000e-04\n",
            "Epoch 222/250\n",
            "390/390 [==============================] - 89s 229ms/step - loss: 0.0973 - accuracy: 0.9652 - val_loss: 0.4254 - val_accuracy: 0.8918 - lr: 1.0000e-04\n",
            "Epoch 223/250\n",
            "390/390 [==============================] - 89s 229ms/step - loss: 0.0934 - accuracy: 0.9671 - val_loss: 0.4235 - val_accuracy: 0.8923 - lr: 1.0000e-04\n",
            "Epoch 224/250\n",
            "390/390 [==============================] - 89s 229ms/step - loss: 0.0959 - accuracy: 0.9663 - val_loss: 0.4225 - val_accuracy: 0.8925 - lr: 1.0000e-04\n",
            "Epoch 225/250\n",
            "390/390 [==============================] - 90s 230ms/step - loss: 0.0979 - accuracy: 0.9644 - val_loss: 0.4229 - val_accuracy: 0.8927 - lr: 1.0000e-04\n",
            "Epoch 226/250\n",
            "390/390 [==============================] - 89s 229ms/step - loss: 0.0962 - accuracy: 0.9655 - val_loss: 0.4222 - val_accuracy: 0.8923 - lr: 1.0000e-04\n",
            "Epoch 227/250\n",
            "390/390 [==============================] - 90s 230ms/step - loss: 0.0986 - accuracy: 0.9648 - val_loss: 0.4205 - val_accuracy: 0.8920 - lr: 1.0000e-04\n",
            "Epoch 228/250\n",
            "390/390 [==============================] - 89s 229ms/step - loss: 0.0976 - accuracy: 0.9651 - val_loss: 0.4227 - val_accuracy: 0.8929 - lr: 1.0000e-04\n",
            "Epoch 229/250\n",
            "390/390 [==============================] - 89s 229ms/step - loss: 0.0930 - accuracy: 0.9668 - val_loss: 0.4213 - val_accuracy: 0.8929 - lr: 1.0000e-04\n",
            "Epoch 230/250\n",
            "390/390 [==============================] - 89s 228ms/step - loss: 0.0966 - accuracy: 0.9659 - val_loss: 0.4275 - val_accuracy: 0.8921 - lr: 1.0000e-04\n",
            "Epoch 231/250\n",
            "390/390 [==============================] - 89s 229ms/step - loss: 0.0952 - accuracy: 0.9661 - val_loss: 0.4266 - val_accuracy: 0.8923 - lr: 1.0000e-04\n",
            "Epoch 232/250\n",
            "390/390 [==============================] - 89s 228ms/step - loss: 0.0941 - accuracy: 0.9658 - val_loss: 0.4251 - val_accuracy: 0.8927 - lr: 1.0000e-04\n",
            "Epoch 233/250\n",
            "390/390 [==============================] - 89s 229ms/step - loss: 0.0976 - accuracy: 0.9647 - val_loss: 0.4254 - val_accuracy: 0.8915 - lr: 1.0000e-04\n",
            "Epoch 234/250\n",
            "390/390 [==============================] - 90s 230ms/step - loss: 0.0938 - accuracy: 0.9667 - val_loss: 0.4272 - val_accuracy: 0.8924 - lr: 1.0000e-04\n",
            "Epoch 235/250\n",
            "390/390 [==============================] - 89s 229ms/step - loss: 0.0965 - accuracy: 0.9650 - val_loss: 0.4252 - val_accuracy: 0.8924 - lr: 1.0000e-04\n",
            "Epoch 236/250\n",
            "390/390 [==============================] - 89s 229ms/step - loss: 0.0960 - accuracy: 0.9659 - val_loss: 0.4250 - val_accuracy: 0.8928 - lr: 1.0000e-04\n",
            "Epoch 237/250\n",
            "390/390 [==============================] - 89s 229ms/step - loss: 0.0958 - accuracy: 0.9655 - val_loss: 0.4232 - val_accuracy: 0.8931 - lr: 1.0000e-04\n",
            "Epoch 238/250\n",
            "390/390 [==============================] - 89s 229ms/step - loss: 0.0940 - accuracy: 0.9670 - val_loss: 0.4270 - val_accuracy: 0.8922 - lr: 1.0000e-04\n",
            "Epoch 239/250\n",
            "390/390 [==============================] - 89s 228ms/step - loss: 0.0932 - accuracy: 0.9663 - val_loss: 0.4243 - val_accuracy: 0.8923 - lr: 1.0000e-04\n",
            "Epoch 240/250\n",
            "390/390 [==============================] - 90s 230ms/step - loss: 0.0936 - accuracy: 0.9660 - val_loss: 0.4225 - val_accuracy: 0.8921 - lr: 1.0000e-04\n",
            "Epoch 241/250\n",
            "390/390 [==============================] - 89s 229ms/step - loss: 0.0951 - accuracy: 0.9658 - val_loss: 0.4226 - val_accuracy: 0.8929 - lr: 1.0000e-04\n",
            "Epoch 242/250\n",
            "390/390 [==============================] - 89s 228ms/step - loss: 0.0955 - accuracy: 0.9662 - val_loss: 0.4229 - val_accuracy: 0.8928 - lr: 1.0000e-04\n",
            "Epoch 243/250\n",
            "390/390 [==============================] - 89s 229ms/step - loss: 0.0976 - accuracy: 0.9655 - val_loss: 0.4249 - val_accuracy: 0.8926 - lr: 1.0000e-04\n",
            "Epoch 244/250\n",
            "390/390 [==============================] - 89s 229ms/step - loss: 0.0924 - accuracy: 0.9668 - val_loss: 0.4239 - val_accuracy: 0.8931 - lr: 1.0000e-04\n",
            "Epoch 245/250\n",
            "390/390 [==============================] - 89s 229ms/step - loss: 0.0971 - accuracy: 0.9662 - val_loss: 0.4267 - val_accuracy: 0.8922 - lr: 1.0000e-04\n",
            "Epoch 246/250\n",
            "390/390 [==============================] - 89s 229ms/step - loss: 0.0964 - accuracy: 0.9663 - val_loss: 0.4252 - val_accuracy: 0.8923 - lr: 1.0000e-04\n",
            "Epoch 247/250\n",
            "390/390 [==============================] - 89s 229ms/step - loss: 0.0950 - accuracy: 0.9662 - val_loss: 0.4256 - val_accuracy: 0.8920 - lr: 1.0000e-04\n",
            "Epoch 248/250\n",
            "390/390 [==============================] - 89s 228ms/step - loss: 0.0927 - accuracy: 0.9666 - val_loss: 0.4219 - val_accuracy: 0.8937 - lr: 1.0000e-04\n",
            "Epoch 249/250\n",
            "390/390 [==============================] - 89s 229ms/step - loss: 0.0948 - accuracy: 0.9669 - val_loss: 0.4246 - val_accuracy: 0.8941 - lr: 1.0000e-04\n",
            "Epoch 250/250\n",
            "390/390 [==============================] - 89s 229ms/step - loss: 0.0956 - accuracy: 0.9663 - val_loss: 0.4247 - val_accuracy: 0.8932 - lr: 1.0000e-04\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x2951a775fa0>"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.fit(datagen.flow(x_train, y_train, batch_size=128), callbacks=[reduced_lr], steps_per_epoch = len(x_train) // 128, epochs = 250, validation_data=(x_test, y_test), verbose = 1)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "resnet_32(cifar 10)",
      "provenance": []
    },
    "interpreter": {
      "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
    },
    "kernelspec": {
      "display_name": "Python 3.9.7 ('base')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
