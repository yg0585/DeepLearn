{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_RJPHSIttxbg",
        "outputId": "afe33b80-bd54-454a-ce6e-64bdb7f7a5d8"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "FfSglge_vtMX"
      },
      "outputs": [],
      "source": [
        "datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "    rotation_range = 15,\n",
        "    horizontal_flip= True,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1\n",
        ")\n",
        "datagen.fit(x_train)\n",
        "\n",
        "x_train = x_train.astype(\"float32\")\n",
        "x_test = x_test.astype(\"float32\")\n",
        "mean = np.mean(x_train)\n",
        "std = np.std(x_train)\n",
        "x_test = (x_test - mean) / std\n",
        "x_train = (x_train - mean) / std\n",
        "y_train = tf.keras.utils.to_categorical(y_train, 10)\n",
        "y_test = tf.keras.utils.to_categorical(y_test, 10)\n",
        "def lr_schedule(epoch):\n",
        "  if epoch > 200 :\n",
        "    return 0.0001\n",
        "  if epoch > 80 :\n",
        "    return 0.001\n",
        "  if epoch > 50 :\n",
        "    return 0.005\n",
        "  return 0.01\n",
        "  \n",
        "reduced_lr = tf.keras.callbacks.LearningRateScheduler(lr_schedule)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "def bottleneck(t, inc, ouc, n, s, x):\n",
        "    x_input = x\n",
        "    strides = [s] + [1] * (n - 1)\n",
        "    for stride in strides:\n",
        "        x = tf.keras.layers.Conv2D(filters = inc * t, kernel_size= (1, 1), strides = 1, padding = 'SAME'\n",
        "                                   , kernel_initializer=tf.keras.initializers.he_normal(), kernel_regularizer=tf.keras.regularizers.l2(0.0004))(x)\n",
        "        x = tf.keras.layers.BatchNormalization(epsilon=1e-3, momentum=0.999)(x)\n",
        "        x = tf.nn.relu6(x)\n",
        "        x = tf.keras.layers.DepthwiseConv2D(kernel_size= (3, 3), strides=stride, padding='same', kernel_initializer=tf.keras.initializers.he_normal(), kernel_regularizer=tf.keras.regularizers.l2(0.0004))(x)\n",
        "        x = tf.keras.layers.BatchNormalization(epsilon=1e-3, momentum=0.999)(x)\n",
        "        x = tf.nn.relu6(x)\n",
        "        x = tf.keras.layers.Conv2D(filters = ouc, kernel_size=(1, 1), strides=1,  padding='same', kernel_initializer=tf.keras.initializers.he_normal(), kernel_regularizer=tf.keras.regularizers.l2(0.0004))(x)\n",
        "        x = tf.keras.layers.BatchNormalization(epsilon=1e-3, momentum=0.999)(x)\n",
        "        if stride == 1 :\n",
        "            x_input = tf.keras.layers.Conv2D(filters = ouc, kernel_size=(1, 1), strides=1,  padding='same')(x)\n",
        "            x = tf.keras.layers.Add()([x, x_input])\n",
        "    return x\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 32, 32, 3)]  0           []                               \n",
            "                                                                                                  \n",
            " conv2d (Conv2D)                (None, 32, 32, 32)   896         ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " batch_normalization (BatchNorm  (None, 32, 32, 32)  128         ['conv2d[0][0]']                 \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " conv2d_1 (Conv2D)              (None, 32, 32, 32)   1056        ['batch_normalization[0][0]']    \n",
            "                                                                                                  \n",
            " batch_normalization_1 (BatchNo  (None, 32, 32, 32)  128         ['conv2d_1[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " tf.nn.relu6 (TFOpLambda)       (None, 32, 32, 32)   0           ['batch_normalization_1[0][0]']  \n",
            "                                                                                                  \n",
            " depthwise_conv2d (DepthwiseCon  (None, 32, 32, 32)  320         ['tf.nn.relu6[0][0]']            \n",
            " v2D)                                                                                             \n",
            "                                                                                                  \n",
            " batch_normalization_2 (BatchNo  (None, 32, 32, 32)  128         ['depthwise_conv2d[0][0]']       \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " tf.nn.relu6_1 (TFOpLambda)     (None, 32, 32, 32)   0           ['batch_normalization_2[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_2 (Conv2D)              (None, 32, 32, 16)   528         ['tf.nn.relu6_1[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_3 (BatchNo  (None, 32, 32, 16)  64          ['conv2d_2[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv2d_3 (Conv2D)              (None, 32, 32, 16)   272         ['batch_normalization_3[0][0]']  \n",
            "                                                                                                  \n",
            " add (Add)                      (None, 32, 32, 16)   0           ['batch_normalization_3[0][0]',  \n",
            "                                                                  'conv2d_3[0][0]']               \n",
            "                                                                                                  \n",
            " dropout (Dropout)              (None, 32, 32, 16)   0           ['add[0][0]']                    \n",
            "                                                                                                  \n",
            " conv2d_4 (Conv2D)              (None, 32, 32, 96)   1632        ['dropout[0][0]']                \n",
            "                                                                                                  \n",
            " batch_normalization_4 (BatchNo  (None, 32, 32, 96)  384         ['conv2d_4[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " tf.nn.relu6_2 (TFOpLambda)     (None, 32, 32, 96)   0           ['batch_normalization_4[0][0]']  \n",
            "                                                                                                  \n",
            " depthwise_conv2d_1 (DepthwiseC  (None, 32, 32, 96)  960         ['tf.nn.relu6_2[0][0]']          \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_5 (BatchNo  (None, 32, 32, 96)  384         ['depthwise_conv2d_1[0][0]']     \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " tf.nn.relu6_3 (TFOpLambda)     (None, 32, 32, 96)   0           ['batch_normalization_5[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_5 (Conv2D)              (None, 32, 32, 24)   2328        ['tf.nn.relu6_3[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_6 (BatchNo  (None, 32, 32, 24)  96          ['conv2d_5[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv2d_6 (Conv2D)              (None, 32, 32, 24)   600         ['batch_normalization_6[0][0]']  \n",
            "                                                                                                  \n",
            " add_1 (Add)                    (None, 32, 32, 24)   0           ['batch_normalization_6[0][0]',  \n",
            "                                                                  'conv2d_6[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_7 (Conv2D)              (None, 32, 32, 96)   2400        ['add_1[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_7 (BatchNo  (None, 32, 32, 96)  384         ['conv2d_7[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " tf.nn.relu6_4 (TFOpLambda)     (None, 32, 32, 96)   0           ['batch_normalization_7[0][0]']  \n",
            "                                                                                                  \n",
            " depthwise_conv2d_2 (DepthwiseC  (None, 32, 32, 96)  960         ['tf.nn.relu6_4[0][0]']          \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_8 (BatchNo  (None, 32, 32, 96)  384         ['depthwise_conv2d_2[0][0]']     \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " tf.nn.relu6_5 (TFOpLambda)     (None, 32, 32, 96)   0           ['batch_normalization_8[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_8 (Conv2D)              (None, 32, 32, 24)   2328        ['tf.nn.relu6_5[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_9 (BatchNo  (None, 32, 32, 24)  96          ['conv2d_8[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv2d_9 (Conv2D)              (None, 32, 32, 24)   600         ['batch_normalization_9[0][0]']  \n",
            "                                                                                                  \n",
            " add_2 (Add)                    (None, 32, 32, 24)   0           ['batch_normalization_9[0][0]',  \n",
            "                                                                  'conv2d_9[0][0]']               \n",
            "                                                                                                  \n",
            " dropout_1 (Dropout)            (None, 32, 32, 24)   0           ['add_2[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_10 (Conv2D)             (None, 32, 32, 144)  3600        ['dropout_1[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_10 (BatchN  (None, 32, 32, 144)  576        ['conv2d_10[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " tf.nn.relu6_6 (TFOpLambda)     (None, 32, 32, 144)  0           ['batch_normalization_10[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_3 (DepthwiseC  (None, 32, 32, 144)  1440       ['tf.nn.relu6_6[0][0]']          \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_11 (BatchN  (None, 32, 32, 144)  576        ['depthwise_conv2d_3[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " tf.nn.relu6_7 (TFOpLambda)     (None, 32, 32, 144)  0           ['batch_normalization_11[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_11 (Conv2D)             (None, 32, 32, 32)   4640        ['tf.nn.relu6_7[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_12 (BatchN  (None, 32, 32, 32)  128         ['conv2d_11[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_12 (Conv2D)             (None, 32, 32, 32)   1056        ['batch_normalization_12[0][0]'] \n",
            "                                                                                                  \n",
            " add_3 (Add)                    (None, 32, 32, 32)   0           ['batch_normalization_12[0][0]', \n",
            "                                                                  'conv2d_12[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_13 (Conv2D)             (None, 32, 32, 144)  4752        ['add_3[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_13 (BatchN  (None, 32, 32, 144)  576        ['conv2d_13[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " tf.nn.relu6_8 (TFOpLambda)     (None, 32, 32, 144)  0           ['batch_normalization_13[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_4 (DepthwiseC  (None, 32, 32, 144)  1440       ['tf.nn.relu6_8[0][0]']          \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_14 (BatchN  (None, 32, 32, 144)  576        ['depthwise_conv2d_4[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " tf.nn.relu6_9 (TFOpLambda)     (None, 32, 32, 144)  0           ['batch_normalization_14[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_14 (Conv2D)             (None, 32, 32, 32)   4640        ['tf.nn.relu6_9[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_15 (BatchN  (None, 32, 32, 32)  128         ['conv2d_14[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_15 (Conv2D)             (None, 32, 32, 32)   1056        ['batch_normalization_15[0][0]'] \n",
            "                                                                                                  \n",
            " add_4 (Add)                    (None, 32, 32, 32)   0           ['batch_normalization_15[0][0]', \n",
            "                                                                  'conv2d_15[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_16 (Conv2D)             (None, 32, 32, 144)  4752        ['add_4[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_16 (BatchN  (None, 32, 32, 144)  576        ['conv2d_16[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " tf.nn.relu6_10 (TFOpLambda)    (None, 32, 32, 144)  0           ['batch_normalization_16[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_5 (DepthwiseC  (None, 32, 32, 144)  1440       ['tf.nn.relu6_10[0][0]']         \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_17 (BatchN  (None, 32, 32, 144)  576        ['depthwise_conv2d_5[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " tf.nn.relu6_11 (TFOpLambda)    (None, 32, 32, 144)  0           ['batch_normalization_17[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_17 (Conv2D)             (None, 32, 32, 32)   4640        ['tf.nn.relu6_11[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_18 (BatchN  (None, 32, 32, 32)  128         ['conv2d_17[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_18 (Conv2D)             (None, 32, 32, 32)   1056        ['batch_normalization_18[0][0]'] \n",
            "                                                                                                  \n",
            " add_5 (Add)                    (None, 32, 32, 32)   0           ['batch_normalization_18[0][0]', \n",
            "                                                                  'conv2d_18[0][0]']              \n",
            "                                                                                                  \n",
            " dropout_2 (Dropout)            (None, 32, 32, 32)   0           ['add_5[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_19 (Conv2D)             (None, 32, 32, 192)  6336        ['dropout_2[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_19 (BatchN  (None, 32, 32, 192)  768        ['conv2d_19[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " tf.nn.relu6_12 (TFOpLambda)    (None, 32, 32, 192)  0           ['batch_normalization_19[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_6 (DepthwiseC  (None, 16, 16, 192)  1920       ['tf.nn.relu6_12[0][0]']         \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_20 (BatchN  (None, 16, 16, 192)  768        ['depthwise_conv2d_6[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " tf.nn.relu6_13 (TFOpLambda)    (None, 16, 16, 192)  0           ['batch_normalization_20[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_20 (Conv2D)             (None, 16, 16, 64)   12352       ['tf.nn.relu6_13[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_21 (BatchN  (None, 16, 16, 64)  256         ['conv2d_20[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_21 (Conv2D)             (None, 16, 16, 192)  12480       ['batch_normalization_21[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_22 (BatchN  (None, 16, 16, 192)  768        ['conv2d_21[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " tf.nn.relu6_14 (TFOpLambda)    (None, 16, 16, 192)  0           ['batch_normalization_22[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_7 (DepthwiseC  (None, 16, 16, 192)  1920       ['tf.nn.relu6_14[0][0]']         \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_23 (BatchN  (None, 16, 16, 192)  768        ['depthwise_conv2d_7[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " tf.nn.relu6_15 (TFOpLambda)    (None, 16, 16, 192)  0           ['batch_normalization_23[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_22 (Conv2D)             (None, 16, 16, 64)   12352       ['tf.nn.relu6_15[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_24 (BatchN  (None, 16, 16, 64)  256         ['conv2d_22[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_23 (Conv2D)             (None, 16, 16, 64)   4160        ['batch_normalization_24[0][0]'] \n",
            "                                                                                                  \n",
            " add_6 (Add)                    (None, 16, 16, 64)   0           ['batch_normalization_24[0][0]', \n",
            "                                                                  'conv2d_23[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_24 (Conv2D)             (None, 16, 16, 192)  12480       ['add_6[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_25 (BatchN  (None, 16, 16, 192)  768        ['conv2d_24[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " tf.nn.relu6_16 (TFOpLambda)    (None, 16, 16, 192)  0           ['batch_normalization_25[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_8 (DepthwiseC  (None, 16, 16, 192)  1920       ['tf.nn.relu6_16[0][0]']         \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_26 (BatchN  (None, 16, 16, 192)  768        ['depthwise_conv2d_8[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " tf.nn.relu6_17 (TFOpLambda)    (None, 16, 16, 192)  0           ['batch_normalization_26[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_25 (Conv2D)             (None, 16, 16, 64)   12352       ['tf.nn.relu6_17[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_27 (BatchN  (None, 16, 16, 64)  256         ['conv2d_25[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_26 (Conv2D)             (None, 16, 16, 64)   4160        ['batch_normalization_27[0][0]'] \n",
            "                                                                                                  \n",
            " add_7 (Add)                    (None, 16, 16, 64)   0           ['batch_normalization_27[0][0]', \n",
            "                                                                  'conv2d_26[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_27 (Conv2D)             (None, 16, 16, 192)  12480       ['add_7[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_28 (BatchN  (None, 16, 16, 192)  768        ['conv2d_27[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " tf.nn.relu6_18 (TFOpLambda)    (None, 16, 16, 192)  0           ['batch_normalization_28[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_9 (DepthwiseC  (None, 16, 16, 192)  1920       ['tf.nn.relu6_18[0][0]']         \n",
            " onv2D)                                                                                           \n",
            "                                                                                                  \n",
            " batch_normalization_29 (BatchN  (None, 16, 16, 192)  768        ['depthwise_conv2d_9[0][0]']     \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " tf.nn.relu6_19 (TFOpLambda)    (None, 16, 16, 192)  0           ['batch_normalization_29[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_28 (Conv2D)             (None, 16, 16, 64)   12352       ['tf.nn.relu6_19[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_30 (BatchN  (None, 16, 16, 64)  256         ['conv2d_28[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_29 (Conv2D)             (None, 16, 16, 64)   4160        ['batch_normalization_30[0][0]'] \n",
            "                                                                                                  \n",
            " add_8 (Add)                    (None, 16, 16, 64)   0           ['batch_normalization_30[0][0]', \n",
            "                                                                  'conv2d_29[0][0]']              \n",
            "                                                                                                  \n",
            " dropout_3 (Dropout)            (None, 16, 16, 64)   0           ['add_8[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_30 (Conv2D)             (None, 16, 16, 384)  24960       ['dropout_3[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_31 (BatchN  (None, 16, 16, 384)  1536       ['conv2d_30[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " tf.nn.relu6_20 (TFOpLambda)    (None, 16, 16, 384)  0           ['batch_normalization_31[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_10 (Depthwise  (None, 16, 16, 384)  3840       ['tf.nn.relu6_20[0][0]']         \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_32 (BatchN  (None, 16, 16, 384)  1536       ['depthwise_conv2d_10[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " tf.nn.relu6_21 (TFOpLambda)    (None, 16, 16, 384)  0           ['batch_normalization_32[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_31 (Conv2D)             (None, 16, 16, 96)   36960       ['tf.nn.relu6_21[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_33 (BatchN  (None, 16, 16, 96)  384         ['conv2d_31[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_32 (Conv2D)             (None, 16, 16, 96)   9312        ['batch_normalization_33[0][0]'] \n",
            "                                                                                                  \n",
            " add_9 (Add)                    (None, 16, 16, 96)   0           ['batch_normalization_33[0][0]', \n",
            "                                                                  'conv2d_32[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_33 (Conv2D)             (None, 16, 16, 384)  37248       ['add_9[0][0]']                  \n",
            "                                                                                                  \n",
            " batch_normalization_34 (BatchN  (None, 16, 16, 384)  1536       ['conv2d_33[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " tf.nn.relu6_22 (TFOpLambda)    (None, 16, 16, 384)  0           ['batch_normalization_34[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_11 (Depthwise  (None, 16, 16, 384)  3840       ['tf.nn.relu6_22[0][0]']         \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_35 (BatchN  (None, 16, 16, 384)  1536       ['depthwise_conv2d_11[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " tf.nn.relu6_23 (TFOpLambda)    (None, 16, 16, 384)  0           ['batch_normalization_35[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_34 (Conv2D)             (None, 16, 16, 96)   36960       ['tf.nn.relu6_23[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_36 (BatchN  (None, 16, 16, 96)  384         ['conv2d_34[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_35 (Conv2D)             (None, 16, 16, 96)   9312        ['batch_normalization_36[0][0]'] \n",
            "                                                                                                  \n",
            " add_10 (Add)                   (None, 16, 16, 96)   0           ['batch_normalization_36[0][0]', \n",
            "                                                                  'conv2d_35[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_36 (Conv2D)             (None, 16, 16, 384)  37248       ['add_10[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_37 (BatchN  (None, 16, 16, 384)  1536       ['conv2d_36[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " tf.nn.relu6_24 (TFOpLambda)    (None, 16, 16, 384)  0           ['batch_normalization_37[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_12 (Depthwise  (None, 16, 16, 384)  3840       ['tf.nn.relu6_24[0][0]']         \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_38 (BatchN  (None, 16, 16, 384)  1536       ['depthwise_conv2d_12[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " tf.nn.relu6_25 (TFOpLambda)    (None, 16, 16, 384)  0           ['batch_normalization_38[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_37 (Conv2D)             (None, 16, 16, 96)   36960       ['tf.nn.relu6_25[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_39 (BatchN  (None, 16, 16, 96)  384         ['conv2d_37[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_38 (Conv2D)             (None, 16, 16, 96)   9312        ['batch_normalization_39[0][0]'] \n",
            "                                                                                                  \n",
            " add_11 (Add)                   (None, 16, 16, 96)   0           ['batch_normalization_39[0][0]', \n",
            "                                                                  'conv2d_38[0][0]']              \n",
            "                                                                                                  \n",
            " dropout_4 (Dropout)            (None, 16, 16, 96)   0           ['add_11[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_39 (Conv2D)             (None, 16, 16, 576)  55872       ['dropout_4[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_40 (BatchN  (None, 16, 16, 576)  2304       ['conv2d_39[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " tf.nn.relu6_26 (TFOpLambda)    (None, 16, 16, 576)  0           ['batch_normalization_40[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_13 (Depthwise  (None, 8, 8, 576)   5760        ['tf.nn.relu6_26[0][0]']         \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_41 (BatchN  (None, 8, 8, 576)   2304        ['depthwise_conv2d_13[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " tf.nn.relu6_27 (TFOpLambda)    (None, 8, 8, 576)    0           ['batch_normalization_41[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_40 (Conv2D)             (None, 8, 8, 160)    92320       ['tf.nn.relu6_27[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_42 (BatchN  (None, 8, 8, 160)   640         ['conv2d_40[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_41 (Conv2D)             (None, 8, 8, 576)    92736       ['batch_normalization_42[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_43 (BatchN  (None, 8, 8, 576)   2304        ['conv2d_41[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " tf.nn.relu6_28 (TFOpLambda)    (None, 8, 8, 576)    0           ['batch_normalization_43[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_14 (Depthwise  (None, 8, 8, 576)   5760        ['tf.nn.relu6_28[0][0]']         \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_44 (BatchN  (None, 8, 8, 576)   2304        ['depthwise_conv2d_14[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " tf.nn.relu6_29 (TFOpLambda)    (None, 8, 8, 576)    0           ['batch_normalization_44[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_42 (Conv2D)             (None, 8, 8, 160)    92320       ['tf.nn.relu6_29[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_45 (BatchN  (None, 8, 8, 160)   640         ['conv2d_42[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_43 (Conv2D)             (None, 8, 8, 160)    25760       ['batch_normalization_45[0][0]'] \n",
            "                                                                                                  \n",
            " add_12 (Add)                   (None, 8, 8, 160)    0           ['batch_normalization_45[0][0]', \n",
            "                                                                  'conv2d_43[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_44 (Conv2D)             (None, 8, 8, 576)    92736       ['add_12[0][0]']                 \n",
            "                                                                                                  \n",
            " batch_normalization_46 (BatchN  (None, 8, 8, 576)   2304        ['conv2d_44[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " tf.nn.relu6_30 (TFOpLambda)    (None, 8, 8, 576)    0           ['batch_normalization_46[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_15 (Depthwise  (None, 8, 8, 576)   5760        ['tf.nn.relu6_30[0][0]']         \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_47 (BatchN  (None, 8, 8, 576)   2304        ['depthwise_conv2d_15[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " tf.nn.relu6_31 (TFOpLambda)    (None, 8, 8, 576)    0           ['batch_normalization_47[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_45 (Conv2D)             (None, 8, 8, 160)    92320       ['tf.nn.relu6_31[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_48 (BatchN  (None, 8, 8, 160)   640         ['conv2d_45[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_46 (Conv2D)             (None, 8, 8, 160)    25760       ['batch_normalization_48[0][0]'] \n",
            "                                                                                                  \n",
            " add_13 (Add)                   (None, 8, 8, 160)    0           ['batch_normalization_48[0][0]', \n",
            "                                                                  'conv2d_46[0][0]']              \n",
            "                                                                                                  \n",
            " dropout_5 (Dropout)            (None, 8, 8, 160)    0           ['add_13[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_47 (Conv2D)             (None, 8, 8, 960)    154560      ['dropout_5[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_49 (BatchN  (None, 8, 8, 960)   3840        ['conv2d_47[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " tf.nn.relu6_32 (TFOpLambda)    (None, 8, 8, 960)    0           ['batch_normalization_49[0][0]'] \n",
            "                                                                                                  \n",
            " depthwise_conv2d_16 (Depthwise  (None, 8, 8, 960)   9600        ['tf.nn.relu6_32[0][0]']         \n",
            " Conv2D)                                                                                          \n",
            "                                                                                                  \n",
            " batch_normalization_50 (BatchN  (None, 8, 8, 960)   3840        ['depthwise_conv2d_16[0][0]']    \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " tf.nn.relu6_33 (TFOpLambda)    (None, 8, 8, 960)    0           ['batch_normalization_50[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_48 (Conv2D)             (None, 8, 8, 320)    307520      ['tf.nn.relu6_33[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_51 (BatchN  (None, 8, 8, 320)   1280        ['conv2d_48[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_49 (Conv2D)             (None, 8, 8, 320)    102720      ['batch_normalization_51[0][0]'] \n",
            "                                                                                                  \n",
            " add_14 (Add)                   (None, 8, 8, 320)    0           ['batch_normalization_51[0][0]', \n",
            "                                                                  'conv2d_49[0][0]']              \n",
            "                                                                                                  \n",
            " dropout_6 (Dropout)            (None, 8, 8, 320)    0           ['add_14[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_50 (Conv2D)             (None, 8, 8, 1280)   410880      ['dropout_6[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_52 (BatchN  (None, 8, 8, 1280)  5120        ['conv2d_50[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " global_average_pooling2d (Glob  (None, 1280)        0           ['batch_normalization_52[0][0]'] \n",
            " alAveragePooling2D)                                                                              \n",
            "                                                                                                  \n",
            " flatten (Flatten)              (None, 1280)         0           ['global_average_pooling2d[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 10)           12810       ['flatten[0][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 2,051,098\n",
            "Trainable params: 2,024,410\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\optimizer_v2\\gradient_descent.py:102: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(SGD, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Non-trainable params: 26,688\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "x_input = tf.keras.layers.Input(shape = (32,32,3))\n",
        "x = tf.keras.layers.Conv2D(filters = 32, kernel_size = (3, 3),  strides= (1, 1), padding = 'SAME', kernel_initializer=tf.keras.initializers.he_normal(), kernel_regularizer=tf.keras.regularizers.l2(0.0004))(x_input)\n",
        "x = tf.keras.layers.BatchNormalization(epsilon=1e-3, momentum=0.999)(x)\n",
        "x = bottleneck(1, 32, 16, 1, 1, x)\n",
        "x = tf.keras.layers.Dropout(rate = 0.2)(x)\n",
        "x = bottleneck(6, 16, 24, 2, 1, x)\n",
        "x = tf.keras.layers.Dropout(rate = 0.2)(x)\n",
        "x = bottleneck(6, 24, 32, 3, 1, x)\n",
        "x = tf.keras.layers.Dropout(rate = 0.2)(x)\n",
        "x = bottleneck(6, 32, 64, 4, 2, x)\n",
        "x = tf.keras.layers.Dropout(rate = 0.2)(x)\n",
        "x = bottleneck(6, 64, 96, 3, 1, x)\n",
        "x = tf.keras.layers.Dropout(rate = 0.2)(x)\n",
        "x = bottleneck(6, 96, 160, 3, 2, x)\n",
        "x = tf.keras.layers.Dropout(rate = 0.2)(x)\n",
        "x = bottleneck(6, 160, 320, 1, 1, x)\n",
        "x = tf.keras.layers.Dropout(rate = 0.2)(x)\n",
        "x = tf.keras.layers.Conv2D(filters = 1280, kernel_size=(1, 1), strides=1, padding='same', kernel_initializer=tf.keras.initializers.he_normal(), kernel_regularizer=tf.keras.regularizers.l2(0.0004))(x)\n",
        "x = tf.keras.layers.BatchNormalization(epsilon=1e-3, momentum=0.999)(x)\n",
        "x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
        "x = tf.keras.layers.Flatten()(x)\n",
        "x = tf.keras.layers.Dense(units = 10, activation = 'softmax', kernel_initializer=tf.keras.initializers.he_normal())(x)\n",
        "model = tf.keras.Model(inputs=x_input, outputs = x)\n",
        "model.compile(\n",
        "    loss='categorical_crossentropy',\n",
        "    optimizer=tf.keras.optimizers.SGD(lr=0.045, momentum=0.9),\n",
        "    metrics=['accuracy'],\n",
        ")\n",
        "model.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/250\n",
            "390/390 [==============================] - 102s 243ms/step - loss: 8.2208 - accuracy: 0.3173 - val_loss: 8.5543 - val_accuracy: 0.1000 - lr: 0.0100\n",
            "Epoch 2/250\n",
            "390/390 [==============================] - 89s 228ms/step - loss: 7.4883 - accuracy: 0.4557 - val_loss: 8.2303 - val_accuracy: 0.1000 - lr: 0.0100\n",
            "Epoch 3/250\n",
            "390/390 [==============================] - 92s 236ms/step - loss: 6.9714 - accuracy: 0.5205 - val_loss: 7.9224 - val_accuracy: 0.1000 - lr: 0.0100\n",
            "Epoch 4/250\n",
            "390/390 [==============================] - 93s 238ms/step - loss: 6.5104 - accuracy: 0.5661 - val_loss: 7.6184 - val_accuracy: 0.1000 - lr: 0.0100\n",
            "Epoch 5/250\n",
            "390/390 [==============================] - 93s 238ms/step - loss: 6.0902 - accuracy: 0.6072 - val_loss: 7.4105 - val_accuracy: 0.1000 - lr: 0.0100\n",
            "Epoch 6/250\n",
            "390/390 [==============================] - 93s 238ms/step - loss: 5.7140 - accuracy: 0.6388 - val_loss: 7.0608 - val_accuracy: 0.1000 - lr: 0.0100\n",
            "Epoch 7/250\n",
            "390/390 [==============================] - 93s 237ms/step - loss: 5.3666 - accuracy: 0.6645 - val_loss: 6.8668 - val_accuracy: 0.1000 - lr: 0.0100\n",
            "Epoch 8/250\n",
            "390/390 [==============================] - 93s 238ms/step - loss: 5.0381 - accuracy: 0.6896 - val_loss: 6.6565 - val_accuracy: 0.1000 - lr: 0.0100\n",
            "Epoch 9/250\n",
            "390/390 [==============================] - 93s 238ms/step - loss: 4.7387 - accuracy: 0.7085 - val_loss: 6.5175 - val_accuracy: 0.1000 - lr: 0.0100\n",
            "Epoch 10/250\n",
            "390/390 [==============================] - 93s 238ms/step - loss: 4.4679 - accuracy: 0.7243 - val_loss: 6.5249 - val_accuracy: 0.1000 - lr: 0.0100\n",
            "Epoch 11/250\n",
            "390/390 [==============================] - 93s 238ms/step - loss: 4.2163 - accuracy: 0.7399 - val_loss: 6.3173 - val_accuracy: 0.1430 - lr: 0.0100\n",
            "Epoch 12/250\n",
            "390/390 [==============================] - 93s 238ms/step - loss: 3.9779 - accuracy: 0.7507 - val_loss: 6.0889 - val_accuracy: 0.1225 - lr: 0.0100\n",
            "Epoch 13/250\n",
            "390/390 [==============================] - 93s 238ms/step - loss: 3.7643 - accuracy: 0.7621 - val_loss: 5.7554 - val_accuracy: 0.1431 - lr: 0.0100\n",
            "Epoch 14/250\n",
            "390/390 [==============================] - 93s 238ms/step - loss: 3.5599 - accuracy: 0.7706 - val_loss: 5.8736 - val_accuracy: 0.1695 - lr: 0.0100\n",
            "Epoch 15/250\n",
            "390/390 [==============================] - 93s 238ms/step - loss: 3.3721 - accuracy: 0.7773 - val_loss: 5.3009 - val_accuracy: 0.2044 - lr: 0.0100\n",
            "Epoch 16/250\n",
            "390/390 [==============================] - 93s 238ms/step - loss: 3.1954 - accuracy: 0.7846 - val_loss: 5.2570 - val_accuracy: 0.1665 - lr: 0.0100\n",
            "Epoch 17/250\n",
            "390/390 [==============================] - 93s 238ms/step - loss: 3.0304 - accuracy: 0.7915 - val_loss: 4.6049 - val_accuracy: 0.3004 - lr: 0.0100\n",
            "Epoch 18/250\n",
            "390/390 [==============================] - 93s 238ms/step - loss: 2.8794 - accuracy: 0.7953 - val_loss: 4.4084 - val_accuracy: 0.3361 - lr: 0.0100\n",
            "Epoch 19/250\n",
            "390/390 [==============================] - 93s 237ms/step - loss: 2.7327 - accuracy: 0.8020 - val_loss: 4.3591 - val_accuracy: 0.3052 - lr: 0.0100\n",
            "Epoch 20/250\n",
            "390/390 [==============================] - 93s 238ms/step - loss: 2.5917 - accuracy: 0.8091 - val_loss: 4.1297 - val_accuracy: 0.3284 - lr: 0.0100\n",
            "Epoch 21/250\n",
            "390/390 [==============================] - 92s 237ms/step - loss: 2.4688 - accuracy: 0.8111 - val_loss: 4.0869 - val_accuracy: 0.3219 - lr: 0.0100\n",
            "Epoch 22/250\n",
            "390/390 [==============================] - 89s 228ms/step - loss: 2.3566 - accuracy: 0.8142 - val_loss: 4.0806 - val_accuracy: 0.3046 - lr: 0.0100\n",
            "Epoch 23/250\n",
            "390/390 [==============================] - 89s 228ms/step - loss: 2.2410 - accuracy: 0.8171 - val_loss: 3.5379 - val_accuracy: 0.3902 - lr: 0.0100\n",
            "Epoch 24/250\n",
            "390/390 [==============================] - 89s 228ms/step - loss: 2.1383 - accuracy: 0.8235 - val_loss: 3.9103 - val_accuracy: 0.3098 - lr: 0.0100\n",
            "Epoch 25/250\n",
            "390/390 [==============================] - 89s 229ms/step - loss: 2.0378 - accuracy: 0.8260 - val_loss: 3.5174 - val_accuracy: 0.3961 - lr: 0.0100\n",
            "Epoch 26/250\n",
            "390/390 [==============================] - 89s 228ms/step - loss: 1.9457 - accuracy: 0.8305 - val_loss: 4.0610 - val_accuracy: 0.2756 - lr: 0.0100\n",
            "Epoch 27/250\n",
            "390/390 [==============================] - 89s 228ms/step - loss: 1.8592 - accuracy: 0.8339 - val_loss: 4.1757 - val_accuracy: 0.2330 - lr: 0.0100\n",
            "Epoch 28/250\n",
            "390/390 [==============================] - 91s 232ms/step - loss: 1.7866 - accuracy: 0.8317 - val_loss: 3.4526 - val_accuracy: 0.3906 - lr: 0.0100\n",
            "Epoch 29/250\n",
            "390/390 [==============================] - 93s 238ms/step - loss: 1.7063 - accuracy: 0.8372 - val_loss: 3.2396 - val_accuracy: 0.4056 - lr: 0.0100\n",
            "Epoch 30/250\n",
            "390/390 [==============================] - 93s 238ms/step - loss: 1.6378 - accuracy: 0.8387 - val_loss: 3.1144 - val_accuracy: 0.4293 - lr: 0.0100\n",
            "Epoch 31/250\n",
            "390/390 [==============================] - 93s 238ms/step - loss: 1.5726 - accuracy: 0.8409 - val_loss: 2.5806 - val_accuracy: 0.5473 - lr: 0.0100\n",
            "Epoch 32/250\n",
            "390/390 [==============================] - 93s 238ms/step - loss: 1.5073 - accuracy: 0.8451 - val_loss: 3.0909 - val_accuracy: 0.4049 - lr: 0.0100\n",
            "Epoch 33/250\n",
            "390/390 [==============================] - 93s 238ms/step - loss: 1.4468 - accuracy: 0.8468 - val_loss: 2.8173 - val_accuracy: 0.4550 - lr: 0.0100\n",
            "Epoch 34/250\n",
            "390/390 [==============================] - 93s 238ms/step - loss: 1.3921 - accuracy: 0.8483 - val_loss: 2.7125 - val_accuracy: 0.4782 - lr: 0.0100\n",
            "Epoch 35/250\n",
            "390/390 [==============================] - 93s 238ms/step - loss: 1.3424 - accuracy: 0.8493 - val_loss: 2.1300 - val_accuracy: 0.5888 - lr: 0.0100\n",
            "Epoch 36/250\n",
            "390/390 [==============================] - 93s 238ms/step - loss: 1.2988 - accuracy: 0.8509 - val_loss: 2.3105 - val_accuracy: 0.5443 - lr: 0.0100\n",
            "Epoch 37/250\n",
            "390/390 [==============================] - 93s 238ms/step - loss: 1.2519 - accuracy: 0.8537 - val_loss: 2.2502 - val_accuracy: 0.5620 - lr: 0.0100\n",
            "Epoch 38/250\n",
            "390/390 [==============================] - 93s 238ms/step - loss: 1.2117 - accuracy: 0.8528 - val_loss: 1.9127 - val_accuracy: 0.6334 - lr: 0.0100\n",
            "Epoch 39/250\n",
            "390/390 [==============================] - 93s 238ms/step - loss: 1.1722 - accuracy: 0.8550 - val_loss: 1.7469 - val_accuracy: 0.6825 - lr: 0.0100\n",
            "Epoch 40/250\n",
            "390/390 [==============================] - 93s 238ms/step - loss: 1.1305 - accuracy: 0.8580 - val_loss: 2.1533 - val_accuracy: 0.5495 - lr: 0.0100\n",
            "Epoch 41/250\n",
            "390/390 [==============================] - 93s 238ms/step - loss: 1.1005 - accuracy: 0.8591 - val_loss: 1.6051 - val_accuracy: 0.6872 - lr: 0.0100\n",
            "Epoch 42/250\n",
            "390/390 [==============================] - 93s 239ms/step - loss: 1.0691 - accuracy: 0.8584 - val_loss: 1.4041 - val_accuracy: 0.7457 - lr: 0.0100\n",
            "Epoch 43/250\n",
            "390/390 [==============================] - 93s 238ms/step - loss: 1.0365 - accuracy: 0.8609 - val_loss: 1.4965 - val_accuracy: 0.7149 - lr: 0.0100\n",
            "Epoch 44/250\n",
            "390/390 [==============================] - 93s 238ms/step - loss: 1.0072 - accuracy: 0.8607 - val_loss: 1.2231 - val_accuracy: 0.7875 - lr: 0.0100\n",
            "Epoch 45/250\n",
            "390/390 [==============================] - 93s 238ms/step - loss: 0.9802 - accuracy: 0.8632 - val_loss: 1.5401 - val_accuracy: 0.6865 - lr: 0.0100\n",
            "Epoch 46/250\n",
            "390/390 [==============================] - 85s 218ms/step - loss: 0.9500 - accuracy: 0.8641 - val_loss: 1.5014 - val_accuracy: 0.7109 - lr: 0.0100\n",
            "Epoch 47/250\n",
            "390/390 [==============================] - 79s 203ms/step - loss: 0.9305 - accuracy: 0.8657 - val_loss: 1.2916 - val_accuracy: 0.7448 - lr: 0.0100\n",
            "Epoch 48/250\n",
            "390/390 [==============================] - 79s 203ms/step - loss: 0.9043 - accuracy: 0.8677 - val_loss: 1.3112 - val_accuracy: 0.7383 - lr: 0.0100\n",
            "Epoch 49/250\n",
            "390/390 [==============================] - 93s 239ms/step - loss: 0.8864 - accuracy: 0.8671 - val_loss: 1.2313 - val_accuracy: 0.7550 - lr: 0.0100\n",
            "Epoch 50/250\n",
            "390/390 [==============================] - 93s 238ms/step - loss: 0.8746 - accuracy: 0.8666 - val_loss: 1.0636 - val_accuracy: 0.7974 - lr: 0.0100\n",
            "Epoch 51/250\n",
            "390/390 [==============================] - 93s 238ms/step - loss: 0.8481 - accuracy: 0.8696 - val_loss: 1.0673 - val_accuracy: 0.7900 - lr: 0.0100\n",
            "Epoch 52/250\n",
            "390/390 [==============================] - 93s 239ms/step - loss: 0.7562 - accuracy: 0.8971 - val_loss: 1.2509 - val_accuracy: 0.7406 - lr: 0.0050\n",
            "Epoch 53/250\n",
            "390/390 [==============================] - 93s 238ms/step - loss: 0.7330 - accuracy: 0.8998 - val_loss: 1.2784 - val_accuracy: 0.7238 - lr: 0.0050\n",
            "Epoch 54/250\n",
            "390/390 [==============================] - 93s 239ms/step - loss: 0.7111 - accuracy: 0.9041 - val_loss: 1.3511 - val_accuracy: 0.7062 - lr: 0.0050\n",
            "Epoch 55/250\n",
            "390/390 [==============================] - 93s 238ms/step - loss: 0.7009 - accuracy: 0.9032 - val_loss: 1.4280 - val_accuracy: 0.6858 - lr: 0.0050\n",
            "Epoch 56/250\n",
            "390/390 [==============================] - 93s 238ms/step - loss: 0.6844 - accuracy: 0.9076 - val_loss: 1.1733 - val_accuracy: 0.7424 - lr: 0.0050\n",
            "Epoch 57/250\n",
            "390/390 [==============================] - 93s 238ms/step - loss: 0.6792 - accuracy: 0.9061 - val_loss: 1.0279 - val_accuracy: 0.7876 - lr: 0.0050\n",
            "Epoch 58/250\n",
            "390/390 [==============================] - 93s 239ms/step - loss: 0.6701 - accuracy: 0.9067 - val_loss: 1.1779 - val_accuracy: 0.7508 - lr: 0.0050\n",
            "Epoch 59/250\n",
            "390/390 [==============================] - 93s 238ms/step - loss: 0.6596 - accuracy: 0.9076 - val_loss: 0.9650 - val_accuracy: 0.8047 - lr: 0.0050\n",
            "Epoch 60/250\n",
            "390/390 [==============================] - 93s 238ms/step - loss: 0.6493 - accuracy: 0.9084 - val_loss: 1.3357 - val_accuracy: 0.7121 - lr: 0.0050\n",
            "Epoch 61/250\n",
            "390/390 [==============================] - 93s 239ms/step - loss: 0.6402 - accuracy: 0.9098 - val_loss: 0.9868 - val_accuracy: 0.8015 - lr: 0.0050\n",
            "Epoch 62/250\n",
            "390/390 [==============================] - 93s 239ms/step - loss: 0.6326 - accuracy: 0.9097 - val_loss: 0.9607 - val_accuracy: 0.8021 - lr: 0.0050\n",
            "Epoch 63/250\n",
            "390/390 [==============================] - 93s 240ms/step - loss: 0.6226 - accuracy: 0.9088 - val_loss: 0.8903 - val_accuracy: 0.8193 - lr: 0.0050\n",
            "Epoch 64/250\n",
            "390/390 [==============================] - 93s 239ms/step - loss: 0.6196 - accuracy: 0.9095 - val_loss: 0.8434 - val_accuracy: 0.8393 - lr: 0.0050\n",
            "Epoch 65/250\n",
            "390/390 [==============================] - 93s 239ms/step - loss: 0.6105 - accuracy: 0.9097 - val_loss: 1.0533 - val_accuracy: 0.7835 - lr: 0.0050\n",
            "Epoch 66/250\n",
            "390/390 [==============================] - 93s 239ms/step - loss: 0.6087 - accuracy: 0.9089 - val_loss: 0.8652 - val_accuracy: 0.8289 - lr: 0.0050\n",
            "Epoch 67/250\n",
            "390/390 [==============================] - 93s 239ms/step - loss: 0.5961 - accuracy: 0.9108 - val_loss: 0.8284 - val_accuracy: 0.8374 - lr: 0.0050\n",
            "Epoch 68/250\n",
            "390/390 [==============================] - 93s 239ms/step - loss: 0.5899 - accuracy: 0.9110 - val_loss: 0.9055 - val_accuracy: 0.8179 - lr: 0.0050\n",
            "Epoch 69/250\n",
            "390/390 [==============================] - 93s 239ms/step - loss: 0.5861 - accuracy: 0.9095 - val_loss: 1.1066 - val_accuracy: 0.7728 - lr: 0.0050\n",
            "Epoch 70/250\n",
            "390/390 [==============================] - 93s 239ms/step - loss: 0.5813 - accuracy: 0.9110 - val_loss: 0.8076 - val_accuracy: 0.8412 - lr: 0.0050\n",
            "Epoch 71/250\n",
            "390/390 [==============================] - 93s 239ms/step - loss: 0.5781 - accuracy: 0.9097 - val_loss: 0.8159 - val_accuracy: 0.8385 - lr: 0.0050\n",
            "Epoch 72/250\n",
            "390/390 [==============================] - 93s 239ms/step - loss: 0.5679 - accuracy: 0.9120 - val_loss: 0.8420 - val_accuracy: 0.8365 - lr: 0.0050\n",
            "Epoch 73/250\n",
            "390/390 [==============================] - 93s 239ms/step - loss: 0.5674 - accuracy: 0.9119 - val_loss: 0.9370 - val_accuracy: 0.8067 - lr: 0.0050\n",
            "Epoch 74/250\n",
            "390/390 [==============================] - 93s 239ms/step - loss: 0.5633 - accuracy: 0.9098 - val_loss: 0.8079 - val_accuracy: 0.8427 - lr: 0.0050\n",
            "Epoch 75/250\n",
            "390/390 [==============================] - 93s 239ms/step - loss: 0.5509 - accuracy: 0.9123 - val_loss: 0.7312 - val_accuracy: 0.8619 - lr: 0.0050\n",
            "Epoch 76/250\n",
            "390/390 [==============================] - 93s 239ms/step - loss: 0.5531 - accuracy: 0.9119 - val_loss: 0.8860 - val_accuracy: 0.8223 - lr: 0.0050\n",
            "Epoch 77/250\n",
            "390/390 [==============================] - 93s 239ms/step - loss: 0.5437 - accuracy: 0.9141 - val_loss: 0.7309 - val_accuracy: 0.8536 - lr: 0.0050\n",
            "Epoch 78/250\n",
            "390/390 [==============================] - 93s 239ms/step - loss: 0.5394 - accuracy: 0.9132 - val_loss: 0.7680 - val_accuracy: 0.8501 - lr: 0.0050\n",
            "Epoch 79/250\n",
            "390/390 [==============================] - 93s 239ms/step - loss: 0.5386 - accuracy: 0.9143 - val_loss: 0.7758 - val_accuracy: 0.8436 - lr: 0.0050\n",
            "Epoch 80/250\n",
            "390/390 [==============================] - 93s 239ms/step - loss: 0.5291 - accuracy: 0.9164 - val_loss: 0.7066 - val_accuracy: 0.8664 - lr: 0.0050\n",
            "Epoch 81/250\n",
            "390/390 [==============================] - 93s 239ms/step - loss: 0.5331 - accuracy: 0.9141 - val_loss: 0.7131 - val_accuracy: 0.8647 - lr: 0.0050\n",
            "Epoch 82/250\n",
            "390/390 [==============================] - 93s 239ms/step - loss: 0.4590 - accuracy: 0.9387 - val_loss: 0.5692 - val_accuracy: 0.9038 - lr: 0.0010\n",
            "Epoch 83/250\n",
            "390/390 [==============================] - 93s 239ms/step - loss: 0.4323 - accuracy: 0.9466 - val_loss: 0.5407 - val_accuracy: 0.9102 - lr: 0.0010\n",
            "Epoch 84/250\n",
            "390/390 [==============================] - 93s 239ms/step - loss: 0.4215 - accuracy: 0.9500 - val_loss: 0.5721 - val_accuracy: 0.9047 - lr: 0.0010\n",
            "Epoch 85/250\n",
            "390/390 [==============================] - 93s 239ms/step - loss: 0.4045 - accuracy: 0.9551 - val_loss: 0.5610 - val_accuracy: 0.9058 - lr: 0.0010\n",
            "Epoch 86/250\n",
            "390/390 [==============================] - 93s 239ms/step - loss: 0.4056 - accuracy: 0.9538 - val_loss: 0.5658 - val_accuracy: 0.9063 - lr: 0.0010\n",
            "Epoch 87/250\n",
            "390/390 [==============================] - 93s 239ms/step - loss: 0.3995 - accuracy: 0.9559 - val_loss: 0.5587 - val_accuracy: 0.9092 - lr: 0.0010\n",
            "Epoch 88/250\n",
            "390/390 [==============================] - 93s 239ms/step - loss: 0.3964 - accuracy: 0.9570 - val_loss: 0.5854 - val_accuracy: 0.9013 - lr: 0.0010\n",
            "Epoch 89/250\n",
            "390/390 [==============================] - 93s 239ms/step - loss: 0.3907 - accuracy: 0.9580 - val_loss: 0.5693 - val_accuracy: 0.9082 - lr: 0.0010\n",
            "Epoch 90/250\n",
            "390/390 [==============================] - 93s 239ms/step - loss: 0.3852 - accuracy: 0.9595 - val_loss: 0.5681 - val_accuracy: 0.9072 - lr: 0.0010\n",
            "Epoch 91/250\n",
            "390/390 [==============================] - 93s 239ms/step - loss: 0.3827 - accuracy: 0.9587 - val_loss: 0.6004 - val_accuracy: 0.8988 - lr: 0.0010\n",
            "Epoch 92/250\n",
            "390/390 [==============================] - 89s 229ms/step - loss: 0.3818 - accuracy: 0.9597 - val_loss: 0.5664 - val_accuracy: 0.9079 - lr: 0.0010\n",
            "Epoch 93/250\n",
            "390/390 [==============================] - 89s 229ms/step - loss: 0.3782 - accuracy: 0.9609 - val_loss: 0.6015 - val_accuracy: 0.9005 - lr: 0.0010\n",
            "Epoch 94/250\n",
            "390/390 [==============================] - 89s 228ms/step - loss: 0.3738 - accuracy: 0.9609 - val_loss: 0.5653 - val_accuracy: 0.9069 - lr: 0.0010\n",
            "Epoch 95/250\n",
            "390/390 [==============================] - 89s 229ms/step - loss: 0.3687 - accuracy: 0.9636 - val_loss: 0.5574 - val_accuracy: 0.9104 - lr: 0.0010\n",
            "Epoch 96/250\n",
            "390/390 [==============================] - 89s 228ms/step - loss: 0.3700 - accuracy: 0.9611 - val_loss: 0.5697 - val_accuracy: 0.9080 - lr: 0.0010\n",
            "Epoch 97/250\n",
            "390/390 [==============================] - 89s 229ms/step - loss: 0.3637 - accuracy: 0.9642 - val_loss: 0.5728 - val_accuracy: 0.9051 - lr: 0.0010\n",
            "Epoch 98/250\n",
            "390/390 [==============================] - 89s 229ms/step - loss: 0.3625 - accuracy: 0.9636 - val_loss: 0.5849 - val_accuracy: 0.9059 - lr: 0.0010\n",
            "Epoch 99/250\n",
            "390/390 [==============================] - 89s 228ms/step - loss: 0.3618 - accuracy: 0.9628 - val_loss: 0.5904 - val_accuracy: 0.9032 - lr: 0.0010\n",
            "Epoch 100/250\n",
            "390/390 [==============================] - 89s 228ms/step - loss: 0.3606 - accuracy: 0.9642 - val_loss: 0.5877 - val_accuracy: 0.8999 - lr: 0.0010\n",
            "Epoch 101/250\n",
            "390/390 [==============================] - 89s 228ms/step - loss: 0.3548 - accuracy: 0.9649 - val_loss: 0.6161 - val_accuracy: 0.8935 - lr: 0.0010\n",
            "Epoch 102/250\n",
            "390/390 [==============================] - 89s 228ms/step - loss: 0.3511 - accuracy: 0.9659 - val_loss: 0.6028 - val_accuracy: 0.8971 - lr: 0.0010\n",
            "Epoch 103/250\n",
            "390/390 [==============================] - 91s 234ms/step - loss: 0.3555 - accuracy: 0.9635 - val_loss: 0.5859 - val_accuracy: 0.9036 - lr: 0.0010\n",
            "Epoch 104/250\n",
            "390/390 [==============================] - 93s 239ms/step - loss: 0.3495 - accuracy: 0.9654 - val_loss: 0.5645 - val_accuracy: 0.9070 - lr: 0.0010\n",
            "Epoch 105/250\n",
            "390/390 [==============================] - 93s 239ms/step - loss: 0.3474 - accuracy: 0.9660 - val_loss: 0.5769 - val_accuracy: 0.9040 - lr: 0.0010\n",
            "Epoch 106/250\n",
            "390/390 [==============================] - 93s 239ms/step - loss: 0.3473 - accuracy: 0.9650 - val_loss: 0.5547 - val_accuracy: 0.9092 - lr: 0.0010\n",
            "Epoch 107/250\n",
            "390/390 [==============================] - 93s 239ms/step - loss: 0.3400 - accuracy: 0.9680 - val_loss: 0.5861 - val_accuracy: 0.9026 - lr: 0.0010\n",
            "Epoch 108/250\n",
            "390/390 [==============================] - 93s 239ms/step - loss: 0.3435 - accuracy: 0.9646 - val_loss: 0.5638 - val_accuracy: 0.9077 - lr: 0.0010\n",
            "Epoch 109/250\n",
            "390/390 [==============================] - 93s 239ms/step - loss: 0.3398 - accuracy: 0.9662 - val_loss: 0.5636 - val_accuracy: 0.9048 - lr: 0.0010\n",
            "Epoch 110/250\n",
            "390/390 [==============================] - 93s 239ms/step - loss: 0.3399 - accuracy: 0.9656 - val_loss: 0.6069 - val_accuracy: 0.8970 - lr: 0.0010\n",
            "Epoch 111/250\n",
            "390/390 [==============================] - 93s 239ms/step - loss: 0.3369 - accuracy: 0.9662 - val_loss: 0.5558 - val_accuracy: 0.9120 - lr: 0.0010\n",
            "Epoch 112/250\n",
            "390/390 [==============================] - 93s 239ms/step - loss: 0.3341 - accuracy: 0.9674 - val_loss: 0.5581 - val_accuracy: 0.9097 - lr: 0.0010\n",
            "Epoch 113/250\n",
            "390/390 [==============================] - 93s 239ms/step - loss: 0.3307 - accuracy: 0.9684 - val_loss: 0.5682 - val_accuracy: 0.9068 - lr: 0.0010\n",
            "Epoch 114/250\n",
            "390/390 [==============================] - 93s 239ms/step - loss: 0.3303 - accuracy: 0.9666 - val_loss: 0.6083 - val_accuracy: 0.8965 - lr: 0.0010\n",
            "Epoch 115/250\n",
            "390/390 [==============================] - 93s 239ms/step - loss: 0.3285 - accuracy: 0.9684 - val_loss: 0.5751 - val_accuracy: 0.9039 - lr: 0.0010\n",
            "Epoch 116/250\n",
            "390/390 [==============================] - 93s 239ms/step - loss: 0.3276 - accuracy: 0.9681 - val_loss: 0.6118 - val_accuracy: 0.8985 - lr: 0.0010\n",
            "Epoch 117/250\n",
            "390/390 [==============================] - 93s 239ms/step - loss: 0.3236 - accuracy: 0.9688 - val_loss: 0.5587 - val_accuracy: 0.9074 - lr: 0.0010\n",
            "Epoch 118/250\n",
            "390/390 [==============================] - 93s 239ms/step - loss: 0.3237 - accuracy: 0.9681 - val_loss: 0.5485 - val_accuracy: 0.9093 - lr: 0.0010\n",
            "Epoch 119/250\n",
            "390/390 [==============================] - 93s 239ms/step - loss: 0.3219 - accuracy: 0.9685 - val_loss: 0.5620 - val_accuracy: 0.9071 - lr: 0.0010\n",
            "Epoch 120/250\n",
            "390/390 [==============================] - 93s 239ms/step - loss: 0.3210 - accuracy: 0.9693 - val_loss: 0.5809 - val_accuracy: 0.9027 - lr: 0.0010\n",
            "Epoch 121/250\n",
            "390/390 [==============================] - 93s 239ms/step - loss: 0.3207 - accuracy: 0.9680 - val_loss: 0.5498 - val_accuracy: 0.9109 - lr: 0.0010\n",
            "Epoch 122/250\n",
            "390/390 [==============================] - 92s 235ms/step - loss: 0.3170 - accuracy: 0.9691 - val_loss: 0.5582 - val_accuracy: 0.9083 - lr: 0.0010\n",
            "Epoch 123/250\n",
            "390/390 [==============================] - 89s 228ms/step - loss: 0.3163 - accuracy: 0.9688 - val_loss: 0.5973 - val_accuracy: 0.9018 - lr: 0.0010\n",
            "Epoch 124/250\n",
            "390/390 [==============================] - 89s 228ms/step - loss: 0.3206 - accuracy: 0.9678 - val_loss: 0.5566 - val_accuracy: 0.9081 - lr: 0.0010\n",
            "Epoch 125/250\n",
            "390/390 [==============================] - 89s 229ms/step - loss: 0.3135 - accuracy: 0.9700 - val_loss: 0.5868 - val_accuracy: 0.8992 - lr: 0.0010\n",
            "Epoch 126/250\n",
            "390/390 [==============================] - 89s 228ms/step - loss: 0.3128 - accuracy: 0.9693 - val_loss: 0.5596 - val_accuracy: 0.9074 - lr: 0.0010\n",
            "Epoch 127/250\n",
            "390/390 [==============================] - 89s 228ms/step - loss: 0.3099 - accuracy: 0.9699 - val_loss: 0.5699 - val_accuracy: 0.9046 - lr: 0.0010\n",
            "Epoch 128/250\n",
            "390/390 [==============================] - 89s 228ms/step - loss: 0.3093 - accuracy: 0.9698 - val_loss: 0.5913 - val_accuracy: 0.9023 - lr: 0.0010\n",
            "Epoch 129/250\n",
            "390/390 [==============================] - 89s 228ms/step - loss: 0.3099 - accuracy: 0.9694 - val_loss: 0.5777 - val_accuracy: 0.9038 - lr: 0.0010\n",
            "Epoch 130/250\n",
            "390/390 [==============================] - 89s 228ms/step - loss: 0.3100 - accuracy: 0.9689 - val_loss: 0.6027 - val_accuracy: 0.8994 - lr: 0.0010\n",
            "Epoch 131/250\n",
            "390/390 [==============================] - 89s 228ms/step - loss: 0.3079 - accuracy: 0.9693 - val_loss: 0.5593 - val_accuracy: 0.9090 - lr: 0.0010\n",
            "Epoch 132/250\n",
            "390/390 [==============================] - 89s 228ms/step - loss: 0.3032 - accuracy: 0.9702 - val_loss: 0.5490 - val_accuracy: 0.9082 - lr: 0.0010\n",
            "Epoch 133/250\n",
            "390/390 [==============================] - 89s 228ms/step - loss: 0.3015 - accuracy: 0.9710 - val_loss: 0.5462 - val_accuracy: 0.9119 - lr: 0.0010\n",
            "Epoch 134/250\n",
            "390/390 [==============================] - 89s 228ms/step - loss: 0.3027 - accuracy: 0.9697 - val_loss: 0.5713 - val_accuracy: 0.9040 - lr: 0.0010\n",
            "Epoch 135/250\n",
            "390/390 [==============================] - 89s 228ms/step - loss: 0.2992 - accuracy: 0.9712 - val_loss: 0.5288 - val_accuracy: 0.9168 - lr: 0.0010\n",
            "Epoch 136/250\n",
            "390/390 [==============================] - 89s 228ms/step - loss: 0.2985 - accuracy: 0.9705 - val_loss: 0.5786 - val_accuracy: 0.9021 - lr: 0.0010\n",
            "Epoch 137/250\n",
            "390/390 [==============================] - 89s 228ms/step - loss: 0.2984 - accuracy: 0.9706 - val_loss: 0.5400 - val_accuracy: 0.9115 - lr: 0.0010\n",
            "Epoch 138/250\n",
            "390/390 [==============================] - 89s 228ms/step - loss: 0.2966 - accuracy: 0.9705 - val_loss: 0.6341 - val_accuracy: 0.8906 - lr: 0.0010\n",
            "Epoch 139/250\n",
            "390/390 [==============================] - 89s 228ms/step - loss: 0.2985 - accuracy: 0.9692 - val_loss: 0.6522 - val_accuracy: 0.8863 - lr: 0.0010\n",
            "Epoch 140/250\n",
            "390/390 [==============================] - 89s 228ms/step - loss: 0.2895 - accuracy: 0.9729 - val_loss: 0.5279 - val_accuracy: 0.9122 - lr: 0.0010\n",
            "Epoch 141/250\n",
            "390/390 [==============================] - 89s 228ms/step - loss: 0.2932 - accuracy: 0.9712 - val_loss: 0.6670 - val_accuracy: 0.8849 - lr: 0.0010\n",
            "Epoch 142/250\n",
            "390/390 [==============================] - 89s 228ms/step - loss: 0.2901 - accuracy: 0.9719 - val_loss: 0.5707 - val_accuracy: 0.9056 - lr: 0.0010\n",
            "Epoch 143/250\n",
            "390/390 [==============================] - 89s 228ms/step - loss: 0.2903 - accuracy: 0.9703 - val_loss: 0.5894 - val_accuracy: 0.9006 - lr: 0.0010\n",
            "Epoch 144/250\n",
            "390/390 [==============================] - 89s 228ms/step - loss: 0.2944 - accuracy: 0.9694 - val_loss: 0.5610 - val_accuracy: 0.9062 - lr: 0.0010\n",
            "Epoch 145/250\n",
            "390/390 [==============================] - 89s 228ms/step - loss: 0.2893 - accuracy: 0.9718 - val_loss: 0.5876 - val_accuracy: 0.9013 - lr: 0.0010\n",
            "Epoch 146/250\n",
            "390/390 [==============================] - 89s 228ms/step - loss: 0.2827 - accuracy: 0.9727 - val_loss: 0.5747 - val_accuracy: 0.9013 - lr: 0.0010\n",
            "Epoch 147/250\n",
            "390/390 [==============================] - 89s 228ms/step - loss: 0.2890 - accuracy: 0.9709 - val_loss: 0.5844 - val_accuracy: 0.9000 - lr: 0.0010\n",
            "Epoch 148/250\n",
            "390/390 [==============================] - 89s 228ms/step - loss: 0.2843 - accuracy: 0.9718 - val_loss: 0.5923 - val_accuracy: 0.9024 - lr: 0.0010\n",
            "Epoch 149/250\n",
            "390/390 [==============================] - 89s 228ms/step - loss: 0.2828 - accuracy: 0.9725 - val_loss: 0.5602 - val_accuracy: 0.9046 - lr: 0.0010\n",
            "Epoch 150/250\n",
            "390/390 [==============================] - 89s 228ms/step - loss: 0.2854 - accuracy: 0.9713 - val_loss: 0.6003 - val_accuracy: 0.8981 - lr: 0.0010\n",
            "Epoch 151/250\n",
            "390/390 [==============================] - 89s 228ms/step - loss: 0.2819 - accuracy: 0.9722 - val_loss: 0.5184 - val_accuracy: 0.9152 - lr: 0.0010\n",
            "Epoch 152/250\n",
            "390/390 [==============================] - 89s 228ms/step - loss: 0.2832 - accuracy: 0.9714 - val_loss: 0.5627 - val_accuracy: 0.9062 - lr: 0.0010\n",
            "Epoch 153/250\n",
            "390/390 [==============================] - 89s 228ms/step - loss: 0.2796 - accuracy: 0.9720 - val_loss: 0.5597 - val_accuracy: 0.9065 - lr: 0.0010\n",
            "Epoch 154/250\n",
            "390/390 [==============================] - 89s 228ms/step - loss: 0.2753 - accuracy: 0.9729 - val_loss: 0.5698 - val_accuracy: 0.9044 - lr: 0.0010\n",
            "Epoch 155/250\n",
            "390/390 [==============================] - 89s 228ms/step - loss: 0.2792 - accuracy: 0.9714 - val_loss: 0.5385 - val_accuracy: 0.9115 - lr: 0.0010\n",
            "Epoch 156/250\n",
            "390/390 [==============================] - 89s 229ms/step - loss: 0.2789 - accuracy: 0.9710 - val_loss: 0.5382 - val_accuracy: 0.9085 - lr: 0.0010\n",
            "Epoch 157/250\n",
            "390/390 [==============================] - 89s 228ms/step - loss: 0.2793 - accuracy: 0.9707 - val_loss: 0.5845 - val_accuracy: 0.8991 - lr: 0.0010\n",
            "Epoch 158/250\n",
            "390/390 [==============================] - 89s 228ms/step - loss: 0.2753 - accuracy: 0.9719 - val_loss: 0.5512 - val_accuracy: 0.9055 - lr: 0.0010\n",
            "Epoch 159/250\n",
            "390/390 [==============================] - 89s 228ms/step - loss: 0.2748 - accuracy: 0.9726 - val_loss: 0.5814 - val_accuracy: 0.8988 - lr: 0.0010\n",
            "Epoch 160/250\n",
            "390/390 [==============================] - 89s 228ms/step - loss: 0.2760 - accuracy: 0.9720 - val_loss: 0.6431 - val_accuracy: 0.8897 - lr: 0.0010\n",
            "Epoch 161/250\n",
            "390/390 [==============================] - 89s 228ms/step - loss: 0.2760 - accuracy: 0.9713 - val_loss: 0.5860 - val_accuracy: 0.8983 - lr: 0.0010\n",
            "Epoch 162/250\n",
            "390/390 [==============================] - 89s 228ms/step - loss: 0.2748 - accuracy: 0.9710 - val_loss: 0.5293 - val_accuracy: 0.9113 - lr: 0.0010\n",
            "Epoch 163/250\n",
            "390/390 [==============================] - 89s 228ms/step - loss: 0.2722 - accuracy: 0.9720 - val_loss: 0.5388 - val_accuracy: 0.9087 - lr: 0.0010\n",
            "Epoch 164/250\n",
            "390/390 [==============================] - 89s 229ms/step - loss: 0.2742 - accuracy: 0.9717 - val_loss: 0.5062 - val_accuracy: 0.9139 - lr: 0.0010\n",
            "Epoch 165/250\n",
            "390/390 [==============================] - 89s 228ms/step - loss: 0.2692 - accuracy: 0.9725 - val_loss: 0.5588 - val_accuracy: 0.9046 - lr: 0.0010\n",
            "Epoch 166/250\n",
            "390/390 [==============================] - 89s 228ms/step - loss: 0.2672 - accuracy: 0.9721 - val_loss: 0.5499 - val_accuracy: 0.9034 - lr: 0.0010\n",
            "Epoch 167/250\n",
            "390/390 [==============================] - 89s 228ms/step - loss: 0.2680 - accuracy: 0.9718 - val_loss: 0.6295 - val_accuracy: 0.8896 - lr: 0.0010\n",
            "Epoch 168/250\n",
            "390/390 [==============================] - 89s 228ms/step - loss: 0.2657 - accuracy: 0.9724 - val_loss: 0.5659 - val_accuracy: 0.9031 - lr: 0.0010\n",
            "Epoch 169/250\n",
            "390/390 [==============================] - 89s 228ms/step - loss: 0.2695 - accuracy: 0.9709 - val_loss: 0.5782 - val_accuracy: 0.8995 - lr: 0.0010\n",
            "Epoch 170/250\n",
            "390/390 [==============================] - 89s 228ms/step - loss: 0.2627 - accuracy: 0.9737 - val_loss: 0.5590 - val_accuracy: 0.9042 - lr: 0.0010\n",
            "Epoch 171/250\n",
            "390/390 [==============================] - 89s 228ms/step - loss: 0.2631 - accuracy: 0.9729 - val_loss: 0.5668 - val_accuracy: 0.9021 - lr: 0.0010\n",
            "Epoch 172/250\n",
            "390/390 [==============================] - 89s 228ms/step - loss: 0.2600 - accuracy: 0.9741 - val_loss: 0.5217 - val_accuracy: 0.9092 - lr: 0.0010\n",
            "Epoch 173/250\n",
            "390/390 [==============================] - 89s 228ms/step - loss: 0.2622 - accuracy: 0.9720 - val_loss: 0.5581 - val_accuracy: 0.9066 - lr: 0.0010\n",
            "Epoch 174/250\n",
            "390/390 [==============================] - 89s 228ms/step - loss: 0.2633 - accuracy: 0.9724 - val_loss: 0.6318 - val_accuracy: 0.8888 - lr: 0.0010\n",
            "Epoch 175/250\n",
            "390/390 [==============================] - 89s 228ms/step - loss: 0.2604 - accuracy: 0.9726 - val_loss: 0.5607 - val_accuracy: 0.9027 - lr: 0.0010\n",
            "Epoch 176/250\n",
            "390/390 [==============================] - 89s 228ms/step - loss: 0.2612 - accuracy: 0.9723 - val_loss: 0.5662 - val_accuracy: 0.9001 - lr: 0.0010\n",
            "Epoch 177/250\n",
            "390/390 [==============================] - 89s 228ms/step - loss: 0.2567 - accuracy: 0.9738 - val_loss: 0.5514 - val_accuracy: 0.9051 - lr: 0.0010\n",
            "Epoch 178/250\n",
            "390/390 [==============================] - 89s 228ms/step - loss: 0.2587 - accuracy: 0.9720 - val_loss: 0.4964 - val_accuracy: 0.9147 - lr: 0.0010\n",
            "Epoch 179/250\n",
            "390/390 [==============================] - 89s 228ms/step - loss: 0.2577 - accuracy: 0.9737 - val_loss: 0.5602 - val_accuracy: 0.9060 - lr: 0.0010\n",
            "Epoch 180/250\n",
            "390/390 [==============================] - 89s 228ms/step - loss: 0.2597 - accuracy: 0.9716 - val_loss: 0.5558 - val_accuracy: 0.9037 - lr: 0.0010\n",
            "Epoch 181/250\n",
            "390/390 [==============================] - 89s 228ms/step - loss: 0.2576 - accuracy: 0.9727 - val_loss: 0.5711 - val_accuracy: 0.8984 - lr: 0.0010\n",
            "Epoch 182/250\n",
            "390/390 [==============================] - 89s 228ms/step - loss: 0.2543 - accuracy: 0.9725 - val_loss: 0.5336 - val_accuracy: 0.9061 - lr: 0.0010\n",
            "Epoch 183/250\n",
            "390/390 [==============================] - 93s 239ms/step - loss: 0.2588 - accuracy: 0.9725 - val_loss: 0.5587 - val_accuracy: 0.9010 - lr: 0.0010\n",
            "Epoch 184/250\n",
            "390/390 [==============================] - 93s 239ms/step - loss: 0.2559 - accuracy: 0.9723 - val_loss: 0.5575 - val_accuracy: 0.9006 - lr: 0.0010\n",
            "Epoch 185/250\n",
            "390/390 [==============================] - 93s 239ms/step - loss: 0.2524 - accuracy: 0.9734 - val_loss: 0.5397 - val_accuracy: 0.9028 - lr: 0.0010\n",
            "Epoch 186/250\n",
            "390/390 [==============================] - 93s 239ms/step - loss: 0.2506 - accuracy: 0.9740 - val_loss: 0.5783 - val_accuracy: 0.8998 - lr: 0.0010\n",
            "Epoch 187/250\n",
            "390/390 [==============================] - 93s 239ms/step - loss: 0.2530 - accuracy: 0.9731 - val_loss: 0.5814 - val_accuracy: 0.8990 - lr: 0.0010\n",
            "Epoch 188/250\n",
            "390/390 [==============================] - 93s 239ms/step - loss: 0.2485 - accuracy: 0.9739 - val_loss: 0.7123 - val_accuracy: 0.8771 - lr: 0.0010\n",
            "Epoch 189/250\n",
            "390/390 [==============================] - 93s 239ms/step - loss: 0.2537 - accuracy: 0.9726 - val_loss: 0.5869 - val_accuracy: 0.8977 - lr: 0.0010\n",
            "Epoch 190/250\n",
            "390/390 [==============================] - 93s 239ms/step - loss: 0.2455 - accuracy: 0.9755 - val_loss: 0.5427 - val_accuracy: 0.9074 - lr: 0.0010\n",
            "Epoch 191/250\n",
            "390/390 [==============================] - 93s 239ms/step - loss: 0.2507 - accuracy: 0.9728 - val_loss: 0.5273 - val_accuracy: 0.9090 - lr: 0.0010\n",
            "Epoch 192/250\n",
            "390/390 [==============================] - 93s 239ms/step - loss: 0.2504 - accuracy: 0.9731 - val_loss: 0.5530 - val_accuracy: 0.9027 - lr: 0.0010\n",
            "Epoch 193/250\n",
            "390/390 [==============================] - 93s 239ms/step - loss: 0.2459 - accuracy: 0.9744 - val_loss: 0.5334 - val_accuracy: 0.9079 - lr: 0.0010\n",
            "Epoch 194/250\n",
            "390/390 [==============================] - 93s 239ms/step - loss: 0.2483 - accuracy: 0.9734 - val_loss: 0.5055 - val_accuracy: 0.9103 - lr: 0.0010\n",
            "Epoch 195/250\n",
            "390/390 [==============================] - 93s 239ms/step - loss: 0.2459 - accuracy: 0.9745 - val_loss: 0.5673 - val_accuracy: 0.9006 - lr: 0.0010\n",
            "Epoch 196/250\n",
            "390/390 [==============================] - 93s 239ms/step - loss: 0.2411 - accuracy: 0.9751 - val_loss: 0.5393 - val_accuracy: 0.9041 - lr: 0.0010\n",
            "Epoch 197/250\n",
            "390/390 [==============================] - 93s 239ms/step - loss: 0.2482 - accuracy: 0.9722 - val_loss: 0.5204 - val_accuracy: 0.9095 - lr: 0.0010\n",
            "Epoch 198/250\n",
            "390/390 [==============================] - 93s 238ms/step - loss: 0.2505 - accuracy: 0.9711 - val_loss: 0.5849 - val_accuracy: 0.8969 - lr: 0.0010\n",
            "Epoch 199/250\n",
            "390/390 [==============================] - 93s 239ms/step - loss: 0.2444 - accuracy: 0.9732 - val_loss: 0.5324 - val_accuracy: 0.9041 - lr: 0.0010\n",
            "Epoch 200/250\n",
            "390/390 [==============================] - 93s 239ms/step - loss: 0.2411 - accuracy: 0.9742 - val_loss: 0.5786 - val_accuracy: 0.8946 - lr: 0.0010\n",
            "Epoch 201/250\n",
            "390/390 [==============================] - 93s 239ms/step - loss: 0.2379 - accuracy: 0.9750 - val_loss: 0.5421 - val_accuracy: 0.9031 - lr: 0.0010\n",
            "Epoch 202/250\n",
            "390/390 [==============================] - 93s 239ms/step - loss: 0.2277 - accuracy: 0.9794 - val_loss: 0.4882 - val_accuracy: 0.9163 - lr: 1.0000e-04\n",
            "Epoch 203/250\n",
            "390/390 [==============================] - 93s 239ms/step - loss: 0.2139 - accuracy: 0.9844 - val_loss: 0.4829 - val_accuracy: 0.9213 - lr: 1.0000e-04\n",
            "Epoch 204/250\n",
            "390/390 [==============================] - 93s 239ms/step - loss: 0.2108 - accuracy: 0.9848 - val_loss: 0.4857 - val_accuracy: 0.9203 - lr: 1.0000e-04\n",
            "Epoch 205/250\n",
            "390/390 [==============================] - 93s 238ms/step - loss: 0.2105 - accuracy: 0.9857 - val_loss: 0.4816 - val_accuracy: 0.9215 - lr: 1.0000e-04\n",
            "Epoch 206/250\n",
            "390/390 [==============================] - 93s 239ms/step - loss: 0.2059 - accuracy: 0.9867 - val_loss: 0.4789 - val_accuracy: 0.9220 - lr: 1.0000e-04\n",
            "Epoch 207/250\n",
            "390/390 [==============================] - 93s 239ms/step - loss: 0.2058 - accuracy: 0.9870 - val_loss: 0.4731 - val_accuracy: 0.9224 - lr: 1.0000e-04\n",
            "Epoch 208/250\n",
            "390/390 [==============================] - 93s 239ms/step - loss: 0.2072 - accuracy: 0.9867 - val_loss: 0.4689 - val_accuracy: 0.9229 - lr: 1.0000e-04\n",
            "Epoch 209/250\n",
            "390/390 [==============================] - 93s 238ms/step - loss: 0.2025 - accuracy: 0.9886 - val_loss: 0.4749 - val_accuracy: 0.9220 - lr: 1.0000e-04\n",
            "Epoch 210/250\n",
            "390/390 [==============================] - 93s 238ms/step - loss: 0.2034 - accuracy: 0.9882 - val_loss: 0.4718 - val_accuracy: 0.9221 - lr: 1.0000e-04\n",
            "Epoch 211/250\n",
            "390/390 [==============================] - 93s 238ms/step - loss: 0.2021 - accuracy: 0.9884 - val_loss: 0.4749 - val_accuracy: 0.9218 - lr: 1.0000e-04\n",
            "Epoch 212/250\n",
            "390/390 [==============================] - 93s 239ms/step - loss: 0.2036 - accuracy: 0.9876 - val_loss: 0.4792 - val_accuracy: 0.9215 - lr: 1.0000e-04\n",
            "Epoch 213/250\n",
            "390/390 [==============================] - 93s 239ms/step - loss: 0.2027 - accuracy: 0.9879 - val_loss: 0.4717 - val_accuracy: 0.9230 - lr: 1.0000e-04\n",
            "Epoch 214/250\n",
            "390/390 [==============================] - 93s 238ms/step - loss: 0.2000 - accuracy: 0.9891 - val_loss: 0.4731 - val_accuracy: 0.9231 - lr: 1.0000e-04\n",
            "Epoch 215/250\n",
            "390/390 [==============================] - 93s 239ms/step - loss: 0.2012 - accuracy: 0.9883 - val_loss: 0.4749 - val_accuracy: 0.9223 - lr: 1.0000e-04\n",
            "Epoch 216/250\n",
            "390/390 [==============================] - 93s 238ms/step - loss: 0.1987 - accuracy: 0.9896 - val_loss: 0.4745 - val_accuracy: 0.9230 - lr: 1.0000e-04\n",
            "Epoch 217/250\n",
            "390/390 [==============================] - 93s 238ms/step - loss: 0.1977 - accuracy: 0.9901 - val_loss: 0.4811 - val_accuracy: 0.9202 - lr: 1.0000e-04\n",
            "Epoch 218/250\n",
            "390/390 [==============================] - 89s 228ms/step - loss: 0.1981 - accuracy: 0.9895 - val_loss: 0.4809 - val_accuracy: 0.9208 - lr: 1.0000e-04\n",
            "Epoch 219/250\n",
            "390/390 [==============================] - 89s 228ms/step - loss: 0.1998 - accuracy: 0.9890 - val_loss: 0.4711 - val_accuracy: 0.9229 - lr: 1.0000e-04\n",
            "Epoch 220/250\n",
            "390/390 [==============================] - 89s 228ms/step - loss: 0.1969 - accuracy: 0.9903 - val_loss: 0.4730 - val_accuracy: 0.9224 - lr: 1.0000e-04\n",
            "Epoch 221/250\n",
            "390/390 [==============================] - 89s 229ms/step - loss: 0.1978 - accuracy: 0.9891 - val_loss: 0.4715 - val_accuracy: 0.9227 - lr: 1.0000e-04\n",
            "Epoch 222/250\n",
            "390/390 [==============================] - 93s 239ms/step - loss: 0.1962 - accuracy: 0.9905 - val_loss: 0.4722 - val_accuracy: 0.9228 - lr: 1.0000e-04\n",
            "Epoch 223/250\n",
            "390/390 [==============================] - 93s 239ms/step - loss: 0.1984 - accuracy: 0.9894 - val_loss: 0.4730 - val_accuracy: 0.9232 - lr: 1.0000e-04\n",
            "Epoch 224/250\n",
            "390/390 [==============================] - 93s 239ms/step - loss: 0.1967 - accuracy: 0.9901 - val_loss: 0.4640 - val_accuracy: 0.9239 - lr: 1.0000e-04\n",
            "Epoch 225/250\n",
            "390/390 [==============================] - 93s 239ms/step - loss: 0.1958 - accuracy: 0.9903 - val_loss: 0.4675 - val_accuracy: 0.9257 - lr: 1.0000e-04\n",
            "Epoch 226/250\n",
            "390/390 [==============================] - 93s 239ms/step - loss: 0.1960 - accuracy: 0.9901 - val_loss: 0.4685 - val_accuracy: 0.9248 - lr: 1.0000e-04\n",
            "Epoch 227/250\n",
            "390/390 [==============================] - 93s 239ms/step - loss: 0.1972 - accuracy: 0.9895 - val_loss: 0.4807 - val_accuracy: 0.9235 - lr: 1.0000e-04\n",
            "Epoch 228/250\n",
            "390/390 [==============================] - 93s 239ms/step - loss: 0.1952 - accuracy: 0.9901 - val_loss: 0.4778 - val_accuracy: 0.9222 - lr: 1.0000e-04\n",
            "Epoch 229/250\n",
            "390/390 [==============================] - 93s 239ms/step - loss: 0.1940 - accuracy: 0.9906 - val_loss: 0.4809 - val_accuracy: 0.9225 - lr: 1.0000e-04\n",
            "Epoch 230/250\n",
            "390/390 [==============================] - 93s 239ms/step - loss: 0.1927 - accuracy: 0.9912 - val_loss: 0.4816 - val_accuracy: 0.9223 - lr: 1.0000e-04\n",
            "Epoch 231/250\n",
            "390/390 [==============================] - 93s 239ms/step - loss: 0.1950 - accuracy: 0.9904 - val_loss: 0.4873 - val_accuracy: 0.9207 - lr: 1.0000e-04\n",
            "Epoch 232/250\n",
            "390/390 [==============================] - 93s 239ms/step - loss: 0.1934 - accuracy: 0.9908 - val_loss: 0.4763 - val_accuracy: 0.9247 - lr: 1.0000e-04\n",
            "Epoch 233/250\n",
            "390/390 [==============================] - 93s 239ms/step - loss: 0.1941 - accuracy: 0.9906 - val_loss: 0.4753 - val_accuracy: 0.9238 - lr: 1.0000e-04\n",
            "Epoch 234/250\n",
            "390/390 [==============================] - 93s 239ms/step - loss: 0.1932 - accuracy: 0.9907 - val_loss: 0.4792 - val_accuracy: 0.9248 - lr: 1.0000e-04\n",
            "Epoch 235/250\n",
            "390/390 [==============================] - 93s 239ms/step - loss: 0.1938 - accuracy: 0.9904 - val_loss: 0.4824 - val_accuracy: 0.9222 - lr: 1.0000e-04\n",
            "Epoch 236/250\n",
            "390/390 [==============================] - 93s 239ms/step - loss: 0.1918 - accuracy: 0.9911 - val_loss: 0.4789 - val_accuracy: 0.9231 - lr: 1.0000e-04\n",
            "Epoch 237/250\n",
            "390/390 [==============================] - 93s 239ms/step - loss: 0.1915 - accuracy: 0.9914 - val_loss: 0.4725 - val_accuracy: 0.9257 - lr: 1.0000e-04\n",
            "Epoch 238/250\n",
            "390/390 [==============================] - 92s 237ms/step - loss: 0.1907 - accuracy: 0.9916 - val_loss: 0.4816 - val_accuracy: 0.9232 - lr: 1.0000e-04\n",
            "Epoch 239/250\n",
            "390/390 [==============================] - 89s 228ms/step - loss: 0.1919 - accuracy: 0.9911 - val_loss: 0.4774 - val_accuracy: 0.9231 - lr: 1.0000e-04\n",
            "Epoch 240/250\n",
            "390/390 [==============================] - 89s 228ms/step - loss: 0.1909 - accuracy: 0.9915 - val_loss: 0.4703 - val_accuracy: 0.9249 - lr: 1.0000e-04\n",
            "Epoch 241/250\n",
            "390/390 [==============================] - 89s 228ms/step - loss: 0.1908 - accuracy: 0.9910 - val_loss: 0.4834 - val_accuracy: 0.9227 - lr: 1.0000e-04\n",
            "Epoch 242/250\n",
            "390/390 [==============================] - 89s 228ms/step - loss: 0.1899 - accuracy: 0.9918 - val_loss: 0.4849 - val_accuracy: 0.9232 - lr: 1.0000e-04\n",
            "Epoch 243/250\n",
            "390/390 [==============================] - 89s 228ms/step - loss: 0.1904 - accuracy: 0.9914 - val_loss: 0.4834 - val_accuracy: 0.9222 - lr: 1.0000e-04\n",
            "Epoch 244/250\n",
            "390/390 [==============================] - 89s 228ms/step - loss: 0.1900 - accuracy: 0.9917 - val_loss: 0.4814 - val_accuracy: 0.9236 - lr: 1.0000e-04\n",
            "Epoch 245/250\n",
            "390/390 [==============================] - 89s 228ms/step - loss: 0.1892 - accuracy: 0.9913 - val_loss: 0.4800 - val_accuracy: 0.9225 - lr: 1.0000e-04\n",
            "Epoch 246/250\n",
            "390/390 [==============================] - 93s 238ms/step - loss: 0.1903 - accuracy: 0.9911 - val_loss: 0.4739 - val_accuracy: 0.9257 - lr: 1.0000e-04\n",
            "Epoch 247/250\n",
            "390/390 [==============================] - 93s 238ms/step - loss: 0.1906 - accuracy: 0.9911 - val_loss: 0.4765 - val_accuracy: 0.9238 - lr: 1.0000e-04\n",
            "Epoch 248/250\n",
            "390/390 [==============================] - 93s 238ms/step - loss: 0.1902 - accuracy: 0.9914 - val_loss: 0.4806 - val_accuracy: 0.9246 - lr: 1.0000e-04\n",
            "Epoch 249/250\n",
            "390/390 [==============================] - 93s 238ms/step - loss: 0.1901 - accuracy: 0.9912 - val_loss: 0.4780 - val_accuracy: 0.9242 - lr: 1.0000e-04\n",
            "Epoch 250/250\n",
            "390/390 [==============================] - 93s 238ms/step - loss: 0.1900 - accuracy: 0.9912 - val_loss: 0.4743 - val_accuracy: 0.9244 - lr: 1.0000e-04\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x1e7253afc10>"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.fit(datagen.flow(x_train, y_train, batch_size=128), callbacks=[reduced_lr], steps_per_epoch = len(x_train) // 128, epochs = 250, validation_data=(x_test, y_test), verbose = 1)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "resnet_32(cifar 10)",
      "provenance": []
    },
    "interpreter": {
      "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
    },
    "kernelspec": {
      "display_name": "Python 3.9.7 ('base')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
